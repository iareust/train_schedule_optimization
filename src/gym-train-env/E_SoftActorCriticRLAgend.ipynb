{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "from tf_agents.agents.ddpg import critic_network\n",
    "from tf_agents.agents.sac import sac_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.networks import normal_projection_network\n",
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import gym_train_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"train-tf-v1\"\n",
    "\n",
    "# use \"num_iterations = 1e6\" for better results,\n",
    "num_iterations = 100000\n",
    "\n",
    "initial_collect_steps = 1000 \n",
    "collect_steps_per_iteration = 1 \n",
    "replay_buffer_capacity = 1000000 \n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "critic_learning_rate = 3e-4 \n",
    "actor_learning_rate = 3e-4 \n",
    "alpha_learning_rate = 3e-4 \n",
    "target_update_tau = 0.005 \n",
    "target_update_period = 1\n",
    "gamma = 0.99 \n",
    "reward_scale_factor = 1.0 \n",
    "gradient_clipping = None \n",
    "\n",
    "actor_fc_layer_params = (256, 256)\n",
    "critic_joint_fc_layer_params = (256, 256)\n",
    "\n",
    "log_interval = 5 \n",
    "\n",
    "num_eval_episodes = 30\n",
    "eval_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([1.  , 0.03, 0.  , 0.  , 0.03, 1.  , 0.03, 0.02, 0.  , 0.03, 1.  ,\n",
       "       0.01, 0.  , 0.02, 0.01, 1.  , 0.  , 0.25, 0.  , 0.  , 0.25, 0.  ,\n",
       "       0.3 , 0.4 , 0.  , 0.3 , 0.  , 0.8 , 0.  , 0.4 , 0.8 , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 ]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = suite_gym.load(env_name)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_spec = train_env.observation_spec()\n",
    "action_spec = train_env.action_spec()\n",
    "critic_net = critic_network.CriticNetwork(\n",
    "    (observation_spec, action_spec),\n",
    "    observation_fc_layer_params=None,\n",
    "    action_fc_layer_params=None,\n",
    "    joint_fc_layer_params=critic_joint_fc_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_projection_net(action_spec,init_means_output_factor=0.1):\n",
    "  return normal_projection_network.NormalProjectionNetwork(\n",
    "      action_spec,\n",
    "      mean_transform=None,\n",
    "      state_dependent_std=True,\n",
    "      init_means_output_factor=init_means_output_factor,\n",
    "      std_transform=sac_agent.std_clip_transform,\n",
    "      scale_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    observation_spec,\n",
    "    action_spec,\n",
    "    fc_layer_params=actor_fc_layer_params,\n",
    "    continuous_projection_net=normal_projection_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer CriticNetwork is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer CriticNetwork is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer TargetCriticNetwork1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer TargetCriticNetwork1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer CriticNetwork2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer CriticNetwork2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer TargetCriticNetwork2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer TargetCriticNetwork2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer ActorDistributionNetwork is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer ActorDistributionNetwork is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "tf_agent = sac_agent.SacAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    action_spec,\n",
    "    actor_network=actor_net,\n",
    "    critic_network=critic_net,\n",
    "    actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=actor_learning_rate),\n",
    "    critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=critic_learning_rate),\n",
    "    alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=alpha_learning_rate),\n",
    "    target_update_tau=target_update_tau,\n",
    "    target_update_period=target_update_period,\n",
    "    td_errors_loss_fn=tf.compat.v1.losses.mean_squared_error,\n",
    "    gamma=gamma,\n",
    "    reward_scale_factor=reward_scale_factor,\n",
    "    gradient_clipping=gradient_clipping,\n",
    "    train_step_counter=global_step)\n",
    "tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = greedy_policy.GreedyPolicy(tf_agent.policy)\n",
    "collect_policy = tf_agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=5):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "compute_avg_return(eval_env, eval_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=tf_agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 51), dtype=float64, numpy=\n",
       " array([[1.        , 0.03      , 0.        , 0.        , 0.03      ,\n",
       "         1.        , 0.03      , 0.02      , 0.        , 0.03      ,\n",
       "         1.        , 0.01      , 0.        , 0.02      , 0.01      ,\n",
       "         1.        , 0.        , 0.25      , 0.        , 0.        ,\n",
       "         0.25      , 0.        , 0.3       , 0.4       , 0.        ,\n",
       "         0.3       , 0.        , 0.8       , 0.        , 0.4       ,\n",
       "         0.8       , 0.        , 0.19444444, 0.21736111, 0.23402778,\n",
       "         0.16041667, 0.00277778, 0.04583333, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.1       ]])>),\n",
       " ())"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "        train_env,\n",
    "        collect_policy,\n",
    "        observers=[replay_buffer.add_batch],\n",
    "        num_steps=initial_collect_steps)\n",
    "initial_collect_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size, num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    train_env,\n",
    "    collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=collect_steps_per_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5: loss = 472.3922424316406\n",
      "step = 10: loss = 329.2236633300781\n",
      "step = 15: loss = 255.52243041992188\n",
      "step = 20: loss = 255.2845458984375\n",
      "step = 25: loss = 266.1014099121094\n",
      "step = 30: loss = 264.69012451171875\n",
      "step = 35: loss = 270.8209533691406\n",
      "step = 40: loss = 256.78607177734375\n",
      "step = 45: loss = 252.53936767578125\n",
      "step = 50: loss = 245.06507873535156\n",
      "step = 55: loss = 238.94720458984375\n",
      "step = 60: loss = 244.5365753173828\n",
      "step = 65: loss = 248.63687133789062\n",
      "step = 70: loss = 264.3808288574219\n",
      "step = 75: loss = 269.29632568359375\n",
      "step = 80: loss = 276.6889343261719\n",
      "step = 85: loss = 277.90618896484375\n",
      "step = 90: loss = 279.9167175292969\n",
      "step = 95: loss = 300.8321533203125\n",
      "step = 100: loss = 293.3328552246094\n",
      "step = 100: Average Return = 0.0\n",
      " 4:25 -  3:23 -  4:31 -  3: 4 -  5:32 -  5:16 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 105: loss = 284.28924560546875\n",
      "step = 110: loss = 306.034912109375\n",
      "step = 115: loss = 304.2243957519531\n",
      "step = 120: loss = 294.9508972167969\n",
      "step = 125: loss = 294.58642578125\n",
      "step = 130: loss = 313.7825927734375\n",
      "step = 135: loss = 294.7926025390625\n",
      "step = 140: loss = 309.8168029785156\n",
      "step = 145: loss = 293.5867614746094\n",
      "step = 150: loss = 287.3094177246094\n",
      "step = 155: loss = 318.3980407714844\n",
      "step = 160: loss = 313.7023620605469\n",
      "step = 165: loss = 315.6332702636719\n",
      "step = 170: loss = 308.5198974609375\n",
      "step = 175: loss = 306.7663879394531\n",
      "step = 180: loss = 326.6216735839844\n",
      "step = 185: loss = 331.287353515625\n",
      "step = 190: loss = 335.44677734375\n",
      "step = 195: loss = 328.54052734375\n",
      "step = 200: loss = 333.08740234375\n",
      "step = 200: Average Return = 0.0\n",
      " 3:53 -  1:10 -  2:20 -  1:11 -  5:45 -  4:19 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 205: loss = 357.6880798339844\n",
      "step = 210: loss = 345.21112060546875\n",
      "step = 215: loss = 349.362548828125\n",
      "step = 220: loss = 341.5658264160156\n",
      "step = 225: loss = 364.433837890625\n",
      "step = 230: loss = 366.4248962402344\n",
      "step = 235: loss = 392.2127990722656\n",
      "step = 240: loss = 350.6072082519531\n",
      "step = 245: loss = 358.0380554199219\n",
      "step = 250: loss = 375.4345703125\n",
      "step = 255: loss = 398.6756591796875\n",
      "step = 260: loss = 400.8103942871094\n",
      "step = 265: loss = 383.2788391113281\n",
      "step = 270: loss = 397.0336608886719\n",
      "step = 275: loss = 393.0523376464844\n",
      "step = 280: loss = 403.9455261230469\n",
      "step = 285: loss = 412.2067565917969\n",
      "step = 290: loss = 422.01202392578125\n",
      "step = 295: loss = 393.9850769042969\n",
      "step = 300: loss = 400.451904296875\n",
      "step = 300: Average Return = 0.0\n",
      " 3:32 -  0:45 -  1:29 -  2: 7 -  5:50 -  3:43 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 305: loss = 406.88238525390625\n",
      "step = 310: loss = 380.31170654296875\n",
      "step = 315: loss = 394.2352600097656\n",
      "step = 320: loss = 379.1076354980469\n",
      "step = 325: loss = 381.537109375\n",
      "step = 330: loss = 383.1386413574219\n",
      "step = 335: loss = 394.5205078125\n",
      "step = 340: loss = 376.8543395996094\n",
      "step = 345: loss = 409.3473205566406\n",
      "step = 350: loss = 389.8367004394531\n",
      "step = 355: loss = 405.04888916015625\n",
      "step = 360: loss = 430.23797607421875\n",
      "step = 365: loss = 419.87445068359375\n",
      "step = 370: loss = 436.79681396484375\n",
      "step = 375: loss = 407.9487609863281\n",
      "step = 380: loss = 412.71722412109375\n",
      "step = 385: loss = 447.120361328125\n",
      "step = 390: loss = 426.021484375\n",
      "step = 395: loss = 440.76983642578125\n",
      "step = 400: loss = 426.64520263671875\n",
      "step = 400: Average Return = 1.0\n",
      " 3:16 -  5: 2 -  0:18 -  0:31 -  5:47 -  0:57 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 405: loss = 439.0911865234375\n",
      "step = 410: loss = 407.98956298828125\n",
      "step = 415: loss = 416.2452392578125\n",
      "step = 420: loss = 417.87908935546875\n",
      "step = 425: loss = 430.5396728515625\n",
      "step = 430: loss = 431.15594482421875\n",
      "step = 435: loss = 427.05926513671875\n",
      "step = 440: loss = 438.3458557128906\n",
      "step = 445: loss = 414.228515625\n",
      "step = 450: loss = 446.8653564453125\n",
      "step = 455: loss = 470.1829833984375\n",
      "step = 460: loss = 468.2019348144531\n",
      "step = 465: loss = 468.3724060058594\n",
      "step = 470: loss = 453.04217529296875\n",
      "step = 475: loss = 462.99658203125\n",
      "step = 480: loss = 488.56500244140625\n",
      "step = 485: loss = 464.5\n",
      "step = 490: loss = 463.01873779296875\n",
      "step = 495: loss = 475.1283264160156\n",
      "step = 500: loss = 475.1961364746094\n",
      "step = 500: Average Return = 1.0\n",
      " 1:37 -  5:40 -  1: 6 -  0:19 -  5:35 -  1:55 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 505: loss = 473.66375732421875\n",
      "step = 510: loss = 475.4519958496094\n",
      "step = 515: loss = 484.4044494628906\n",
      "step = 520: loss = 497.7987060546875\n",
      "step = 525: loss = 491.03851318359375\n",
      "step = 530: loss = 507.72711181640625\n",
      "step = 535: loss = 495.9617919921875\n",
      "step = 540: loss = 499.263671875\n",
      "step = 545: loss = 508.35546875\n",
      "step = 550: loss = 514.912109375\n",
      "step = 555: loss = 521.6135864257812\n",
      "step = 560: loss = 510.2601318359375\n",
      "step = 565: loss = 511.37158203125\n",
      "step = 570: loss = 515.7123413085938\n",
      "step = 575: loss = 518.9970092773438\n",
      "step = 580: loss = 524.23681640625\n",
      "step = 585: loss = 516.2802124023438\n",
      "step = 590: loss = 546.1253051757812\n",
      "step = 595: loss = 535.61328125\n",
      "step = 600: loss = 546.5679931640625\n",
      "step = 600: Average Return = 0.0\n",
      " 5: 5 -  3:35 -  4:52 -  2:25 -  2:54 -  5:32 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 605: loss = 523.9682006835938\n",
      "step = 610: loss = 549.0634765625\n",
      "step = 615: loss = 547.17626953125\n",
      "step = 620: loss = 528.1480712890625\n",
      "step = 625: loss = 552.3890380859375\n",
      "step = 630: loss = 526.7872924804688\n",
      "step = 635: loss = 540.399169921875\n",
      "step = 640: loss = 556.5982055664062\n",
      "step = 645: loss = 558.10400390625\n",
      "step = 650: loss = 573.7515258789062\n",
      "step = 655: loss = 573.9091796875\n",
      "step = 660: loss = 645.4293212890625\n",
      "step = 665: loss = 630.1051635742188\n",
      "step = 670: loss = 643.2723999023438\n",
      "step = 675: loss = 685.1265258789062\n",
      "step = 680: loss = 658.8113403320312\n",
      "step = 685: loss = 718.432373046875\n",
      "step = 690: loss = 651.73681640625\n",
      "step = 695: loss = 690.458251953125\n",
      "step = 700: loss = 696.2669067382812\n",
      "step = 700: Average Return = 1.0\n",
      " 5:26 -  5:46 -  0:18 -  0:16 -  0:32 -  5:33 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 705: loss = 688.7459716796875\n",
      "step = 710: loss = 717.6384887695312\n",
      "step = 715: loss = 657.7278442382812\n",
      "step = 720: loss = 651.2251586914062\n",
      "step = 725: loss = 660.6163330078125\n",
      "step = 730: loss = 649.7360229492188\n",
      "step = 735: loss = 613.9534301757812\n",
      "step = 740: loss = 610.2789306640625\n",
      "step = 745: loss = 614.4623413085938\n",
      "step = 750: loss = 621.5663452148438\n",
      "step = 755: loss = 625.0546875\n",
      "step = 760: loss = 644.6047973632812\n",
      "step = 765: loss = 648.8943481445312\n",
      "step = 770: loss = 645.3704833984375\n",
      "step = 775: loss = 666.854248046875\n",
      "step = 780: loss = 629.5516357421875\n",
      "step = 785: loss = 663.72265625\n",
      "step = 790: loss = 707.728515625\n",
      "step = 795: loss = 751.389892578125\n",
      "step = 800: loss = 772.2803955078125\n",
      "step = 800: Average Return = 1.0\n",
      " 0:18 -  5:17 -  0: 5 -  5:54 -  0:18 -  0:26 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 805: loss = 793.2394409179688\n",
      "step = 810: loss = 811.963134765625\n",
      "step = 815: loss = 760.033447265625\n",
      "step = 820: loss = 820.4646606445312\n",
      "step = 825: loss = 810.4702758789062\n",
      "step = 830: loss = 814.8554077148438\n",
      "step = 835: loss = 851.1813354492188\n",
      "step = 840: loss = 810.9114379882812\n",
      "step = 845: loss = 802.6937866210938\n",
      "step = 850: loss = 827.668212890625\n",
      "step = 855: loss = 805.46630859375\n",
      "step = 860: loss = 792.7938842773438\n",
      "step = 865: loss = 792.50390625\n",
      "step = 870: loss = 822.62939453125\n",
      "step = 875: loss = 755.1460571289062\n",
      "step = 880: loss = 685.5680541992188\n",
      "step = 885: loss = 644.81787109375\n",
      "step = 890: loss = 647.8781127929688\n",
      "step = 895: loss = 669.8759155273438\n",
      "step = 900: loss = 639.7376708984375\n",
      "step = 900: Average Return = 0.0\n",
      " 5:18 -  1: 2 -  3:45 -  5:53 -  2: 9 -  0:13 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 905: loss = 672.21875\n",
      "step = 910: loss = 656.9380493164062\n",
      "step = 915: loss = 607.9716186523438\n",
      "step = 920: loss = 610.4532470703125\n",
      "step = 925: loss = 650.12841796875\n",
      "step = 930: loss = 679.9739379882812\n",
      "step = 935: loss = 597.194091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 940: loss = 651.1392822265625\n",
      "step = 945: loss = 635.4365844726562\n",
      "step = 950: loss = 628.0150146484375\n",
      "step = 955: loss = 659.94140625\n",
      "step = 960: loss = 630.9212646484375\n",
      "step = 965: loss = 641.5733642578125\n",
      "step = 970: loss = 695.7386474609375\n",
      "step = 975: loss = 707.7969970703125\n",
      "step = 980: loss = 694.3424072265625\n",
      "step = 985: loss = 652.544677734375\n",
      "step = 990: loss = 591.896240234375\n",
      "step = 995: loss = 582.3394775390625\n",
      "step = 1000: loss = 605.63671875\n",
      "step = 1000: Average Return = 0.0\n",
      " 3:45 -  2:55 -  1:45 -  5:50 -  2:40 -  0:51 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1005: loss = 608.0790405273438\n",
      "step = 1010: loss = 583.5538940429688\n",
      "step = 1015: loss = 574.7196044921875\n",
      "step = 1020: loss = 552.1671142578125\n",
      "step = 1025: loss = 627.3525390625\n",
      "step = 1030: loss = 588.91162109375\n",
      "step = 1035: loss = 604.9602661132812\n",
      "step = 1040: loss = 616.6787109375\n",
      "step = 1045: loss = 576.9129638671875\n",
      "step = 1050: loss = 560.5123901367188\n",
      "step = 1055: loss = 575.1616821289062\n",
      "step = 1060: loss = 589.0692749023438\n",
      "step = 1065: loss = 594.8318481445312\n",
      "step = 1070: loss = 607.0503540039062\n",
      "step = 1075: loss = 599.1942749023438\n",
      "step = 1080: loss = 578.588134765625\n",
      "step = 1085: loss = 595.3961181640625\n",
      "step = 1090: loss = 588.0443115234375\n",
      "step = 1095: loss = 571.28173828125\n",
      "step = 1100: loss = 572.4920043945312\n",
      "step = 1100: Average Return = 1.0\n",
      " 0:41 -  2:46 -  0:19 -  5:51 -  2:22 -  0:38 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1105: loss = 554.2587280273438\n",
      "step = 1110: loss = 563.391357421875\n",
      "step = 1115: loss = 577.5487670898438\n",
      "step = 1120: loss = 539.5827026367188\n",
      "step = 1125: loss = 550.5673828125\n",
      "step = 1130: loss = 539.3641967773438\n",
      "step = 1135: loss = 552.0506591796875\n",
      "step = 1140: loss = 510.8790588378906\n",
      "step = 1145: loss = 524.9094848632812\n",
      "step = 1150: loss = 498.373046875\n",
      "step = 1155: loss = 515.1431884765625\n",
      "step = 1160: loss = 454.25909423828125\n",
      "step = 1165: loss = 542.6693725585938\n",
      "step = 1170: loss = 504.2458801269531\n",
      "step = 1175: loss = 509.2970886230469\n",
      "step = 1180: loss = 481.891357421875\n",
      "step = 1185: loss = 500.8023681640625\n",
      "step = 1190: loss = 511.8671875\n",
      "step = 1195: loss = 499.8764343261719\n",
      "step = 1200: loss = 515.6206665039062\n",
      "step = 1200: Average Return = 1.0\n",
      " 0:53 -  4:59 -  0:10 -  5:52 -  1:14 -  4:18 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1205: loss = 476.5667724609375\n",
      "step = 1210: loss = 541.770751953125\n",
      "step = 1215: loss = 502.6513671875\n",
      "step = 1220: loss = 507.03045654296875\n",
      "step = 1225: loss = 490.13275146484375\n",
      "step = 1230: loss = 511.0989074707031\n",
      "step = 1235: loss = 496.92236328125\n",
      "step = 1240: loss = 494.5286560058594\n",
      "step = 1245: loss = 497.0625\n",
      "step = 1250: loss = 495.2947692871094\n",
      "step = 1255: loss = 498.5634460449219\n",
      "step = 1260: loss = 470.164794921875\n",
      "step = 1265: loss = 468.6248474121094\n",
      "step = 1270: loss = 425.05328369140625\n",
      "step = 1275: loss = 434.91497802734375\n",
      "step = 1280: loss = 401.90673828125\n",
      "step = 1285: loss = 445.399658203125\n",
      "step = 1290: loss = 409.5042724609375\n",
      "step = 1295: loss = 425.5972595214844\n",
      "step = 1300: loss = 416.84307861328125\n",
      "step = 1300: Average Return = 1.0\n",
      " 2:38 -  5:14 -  2: 7 -  5:25 -  5: 1 -  4:40 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1305: loss = 478.3894348144531\n",
      "step = 1310: loss = 454.34454345703125\n",
      "step = 1315: loss = 477.6402587890625\n",
      "step = 1320: loss = 453.61474609375\n",
      "step = 1325: loss = 478.104248046875\n",
      "step = 1330: loss = 422.2679138183594\n",
      "step = 1335: loss = 495.0286865234375\n",
      "step = 1340: loss = 455.1470642089844\n",
      "step = 1345: loss = 487.6852111816406\n",
      "step = 1350: loss = 462.8799743652344\n",
      "step = 1355: loss = 487.5049133300781\n",
      "step = 1360: loss = 474.02667236328125\n",
      "step = 1365: loss = 535.0162353515625\n",
      "step = 1370: loss = 452.1920166015625\n",
      "step = 1375: loss = 404.3017578125\n",
      "step = 1380: loss = 456.36468505859375\n",
      "step = 1385: loss = 504.2570495605469\n",
      "step = 1390: loss = 483.84100341796875\n",
      "step = 1395: loss = 496.8677978515625\n",
      "step = 1400: loss = 463.0877990722656\n",
      "step = 1400: Average Return = 0.0\n",
      " 2: 2 -  1:57 -  1:38 -  5:49 -  5:44 -  5:26 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1405: loss = 500.6198425292969\n",
      "step = 1410: loss = 481.0179138183594\n",
      "step = 1415: loss = 509.55267333984375\n",
      "step = 1420: loss = 493.93572998046875\n",
      "step = 1425: loss = 510.8564147949219\n",
      "step = 1430: loss = 491.2254638671875\n",
      "step = 1435: loss = 503.2756652832031\n",
      "step = 1440: loss = 484.7259521484375\n",
      "step = 1445: loss = 508.1278381347656\n",
      "step = 1450: loss = 445.6925964355469\n",
      "step = 1455: loss = 427.2779846191406\n",
      "step = 1460: loss = 448.6903076171875\n",
      "step = 1465: loss = 473.50823974609375\n",
      "step = 1470: loss = 461.921875\n",
      "step = 1475: loss = 337.896240234375\n",
      "step = 1480: loss = 419.0189514160156\n",
      "step = 1485: loss = 340.74627685546875\n",
      "step = 1490: loss = 353.3803405761719\n",
      "step = 1495: loss = 315.69287109375\n",
      "step = 1500: loss = 304.3947448730469\n",
      "step = 1500: Average Return = 0.0\n",
      " 2:21 -  1:34 -  3:54 -  4:15 -  5:32 -  5:41 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1505: loss = 339.4077453613281\n",
      "step = 1510: loss = 346.68951416015625\n",
      "step = 1515: loss = 350.02484130859375\n",
      "step = 1520: loss = 350.8291015625\n",
      "step = 1525: loss = 346.8369445800781\n",
      "step = 1530: loss = 330.4052734375\n",
      "step = 1535: loss = 337.5176696777344\n",
      "step = 1540: loss = 338.5702819824219\n",
      "step = 1545: loss = 317.68408203125\n",
      "step = 1550: loss = 318.63189697265625\n",
      "step = 1555: loss = 305.64202880859375\n",
      "step = 1560: loss = 276.6705627441406\n",
      "step = 1565: loss = 247.5988311767578\n",
      "step = 1570: loss = 216.5511932373047\n",
      "step = 1575: loss = 219.99493408203125\n",
      "step = 1580: loss = 240.5203094482422\n",
      "step = 1585: loss = 229.0107421875\n",
      "step = 1590: loss = 247.22129821777344\n",
      "step = 1595: loss = 240.96743774414062\n",
      "step = 1600: loss = 254.36883544921875\n",
      "step = 1600: Average Return = 1.0\n",
      " 0:47 -  1:32 -  1:17 -  1: 4 -  5:53 -  4:11 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1605: loss = 245.97601318359375\n",
      "step = 1610: loss = 271.2857666015625\n",
      "step = 1615: loss = 286.914306640625\n",
      "step = 1620: loss = 318.5651550292969\n",
      "step = 1625: loss = 295.30853271484375\n",
      "step = 1630: loss = 274.7585754394531\n",
      "step = 1635: loss = 265.0553894042969\n",
      "step = 1640: loss = 236.71401977539062\n",
      "step = 1645: loss = 293.180419921875\n",
      "step = 1650: loss = 316.078857421875\n",
      "step = 1655: loss = 351.2799072265625\n",
      "step = 1660: loss = 302.152587890625\n",
      "step = 1665: loss = 241.5339813232422\n",
      "step = 1670: loss = 254.79434204101562\n",
      "step = 1675: loss = 233.14874267578125\n",
      "step = 1680: loss = 278.7010498046875\n",
      "step = 1685: loss = 218.12278747558594\n",
      "step = 1690: loss = 217.9264678955078\n",
      "step = 1695: loss = 243.62940979003906\n",
      "step = 1700: loss = 227.8099822998047\n",
      "step = 1700: Average Return = 1.0\n",
      " 0:13 -  0:52 -  0:44 -  1:48 -  5:50 -  1:58 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1705: loss = 269.9492492675781\n",
      "step = 1710: loss = 259.9646911621094\n",
      "step = 1715: loss = 159.36126708984375\n",
      "step = 1720: loss = 146.3495635986328\n",
      "step = 1725: loss = 126.48065185546875\n",
      "step = 1730: loss = 115.866455078125\n",
      "step = 1735: loss = 140.92291259765625\n",
      "step = 1740: loss = 163.8134002685547\n",
      "step = 1745: loss = 116.1405258178711\n",
      "step = 1750: loss = 80.53873443603516\n",
      "step = 1755: loss = 69.4370346069336\n",
      "step = 1760: loss = 96.94123840332031\n",
      "step = 1765: loss = 109.84037017822266\n",
      "step = 1770: loss = 99.54495239257812\n",
      "step = 1775: loss = 62.29357147216797\n",
      "step = 1780: loss = 68.53057098388672\n",
      "step = 1785: loss = 49.88261795043945\n",
      "step = 1790: loss = 42.96149444580078\n",
      "step = 1795: loss = 36.83604431152344\n",
      "step = 1800: loss = 39.19395446777344\n",
      "step = 1800: Average Return = 4.0\n",
      " 0:30 -  0:51 -  0:58 -  1:14 -  2:24 -  1:24 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1805: loss = 31.46245574951172\n",
      "step = 1810: loss = 1.7165002822875977\n",
      "step = 1815: loss = -3.7532997131347656\n",
      "step = 1820: loss = 3.155366897583008\n",
      "step = 1825: loss = -16.116294860839844\n",
      "step = 1830: loss = -10.287893295288086\n",
      "step = 1835: loss = -19.47844123840332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1840: loss = -20.49597930908203\n",
      "step = 1845: loss = -17.398788452148438\n",
      "step = 1850: loss = -17.713293075561523\n",
      "step = 1855: loss = -11.6035795211792\n",
      "step = 1860: loss = -15.023723602294922\n",
      "step = 1865: loss = -16.440242767333984\n",
      "step = 1870: loss = -10.364795684814453\n",
      "step = 1875: loss = -11.352108001708984\n",
      "step = 1880: loss = -3.3308067321777344\n",
      "step = 1885: loss = -15.49571418762207\n",
      "step = 1890: loss = -21.210508346557617\n",
      "step = 1895: loss = -15.828629493713379\n",
      "step = 1900: loss = -9.496391296386719\n",
      "step = 1900: Average Return = 0.0\n",
      " 0:13 -  0:11 -  0: 6 -  0: 4 -  0:10 -  0:10 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 1905: loss = -8.18746566772461\n",
      "step = 1910: loss = 8.936347961425781\n",
      "step = 1915: loss = -0.7707376480102539\n",
      "step = 1920: loss = -22.05416488647461\n",
      "step = 1925: loss = 7.429924964904785\n",
      "step = 1930: loss = 13.1044282913208\n",
      "step = 1935: loss = -14.935036659240723\n",
      "step = 1940: loss = 12.459793090820312\n",
      "step = 1945: loss = -10.44668197631836\n",
      "step = 1950: loss = -16.361202239990234\n",
      "step = 1955: loss = -14.919356346130371\n",
      "step = 1960: loss = -11.93493938446045\n",
      "step = 1965: loss = -11.734222412109375\n",
      "step = 1970: loss = -5.443221092224121\n",
      "step = 1975: loss = 24.716419219970703\n",
      "step = 1980: loss = -8.279725074768066\n",
      "step = 1985: loss = -8.499135971069336\n",
      "step = 1990: loss = -1.2867441177368164\n",
      "step = 1995: loss = 1.3142786026000977\n",
      "step = 2000: loss = -0.5917463302612305\n",
      "step = 2000: Average Return = 0.0\n",
      " 0:12 -  0: 9 -  0: 7 -  0: 5 -  0:11 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2005: loss = 3.406407356262207\n",
      "step = 2010: loss = -10.738397598266602\n",
      "step = 2015: loss = -0.4134349822998047\n",
      "step = 2020: loss = -6.807769775390625\n",
      "step = 2025: loss = -3.5653982162475586\n",
      "step = 2030: loss = -10.855829238891602\n",
      "step = 2035: loss = -6.872220993041992\n",
      "step = 2040: loss = -6.774633407592773\n",
      "step = 2045: loss = -10.892317771911621\n",
      "step = 2050: loss = -8.19164752960205\n",
      "step = 2055: loss = 2.7735824584960938\n",
      "step = 2060: loss = 8.61873722076416\n",
      "step = 2065: loss = -10.714098930358887\n",
      "step = 2070: loss = -1.7542524337768555\n",
      "step = 2075: loss = 15.302586555480957\n",
      "step = 2080: loss = -6.280651092529297\n",
      "step = 2085: loss = -4.392253875732422\n",
      "step = 2090: loss = -5.989109992980957\n",
      "step = 2095: loss = -8.419522285461426\n",
      "step = 2100: loss = -12.361310958862305\n",
      "step = 2100: Average Return = 0.0\n",
      " 0:11 -  0: 8 -  0: 7 -  0: 5 -  0:11 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2105: loss = -13.234082221984863\n",
      "step = 2110: loss = -6.840115547180176\n",
      "step = 2115: loss = 11.204877853393555\n",
      "step = 2120: loss = -4.905542373657227\n",
      "step = 2125: loss = -4.352347373962402\n",
      "step = 2130: loss = -11.04672622680664\n",
      "step = 2135: loss = -8.14095401763916\n",
      "step = 2140: loss = -10.776357650756836\n",
      "step = 2145: loss = 28.644901275634766\n",
      "step = 2150: loss = -10.119088172912598\n",
      "step = 2155: loss = -16.6569881439209\n",
      "step = 2160: loss = -8.06600570678711\n",
      "step = 2165: loss = -3.9334239959716797\n",
      "step = 2170: loss = -12.090209007263184\n",
      "step = 2175: loss = -12.182586669921875\n",
      "step = 2180: loss = -4.672708511352539\n",
      "step = 2185: loss = -11.338691711425781\n",
      "step = 2190: loss = -10.018843650817871\n",
      "step = 2195: loss = -11.870536804199219\n",
      "step = 2200: loss = -9.136582374572754\n",
      "step = 2200: Average Return = 0.0\n",
      " 0: 9 -  0: 7 -  0: 7 -  0: 6 -  0:11 -  0:10 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2205: loss = -11.195425033569336\n",
      "step = 2210: loss = 2.747420310974121\n",
      "step = 2215: loss = -7.588470458984375\n",
      "step = 2220: loss = -13.048385620117188\n",
      "step = 2225: loss = -14.258783340454102\n",
      "step = 2230: loss = -13.933974266052246\n",
      "step = 2235: loss = -11.695180892944336\n",
      "step = 2240: loss = -14.077841758728027\n",
      "step = 2245: loss = -11.16145133972168\n",
      "step = 2250: loss = -10.249032974243164\n",
      "step = 2255: loss = -13.450984954833984\n",
      "step = 2260: loss = -7.508342742919922\n",
      "step = 2265: loss = -15.856893539428711\n",
      "step = 2270: loss = -17.97199249267578\n",
      "step = 2275: loss = -12.998260498046875\n",
      "step = 2280: loss = -0.29474639892578125\n",
      "step = 2285: loss = -16.949106216430664\n",
      "step = 2290: loss = -11.377729415893555\n",
      "step = 2295: loss = -12.598007202148438\n",
      "step = 2300: loss = -16.300643920898438\n",
      "step = 2300: Average Return = 0.0\n",
      " 0: 8 -  0: 8 -  0: 6 -  0: 8 -  0:11 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2305: loss = -13.47858715057373\n",
      "step = 2310: loss = -14.759532928466797\n",
      "step = 2315: loss = -7.494900703430176\n",
      "step = 2320: loss = -10.910259246826172\n",
      "step = 2325: loss = -21.12120819091797\n",
      "step = 2330: loss = -9.169567108154297\n",
      "step = 2335: loss = -15.31960678100586\n",
      "step = 2340: loss = -19.157955169677734\n",
      "step = 2345: loss = -9.470038414001465\n",
      "step = 2350: loss = -16.930904388427734\n",
      "step = 2355: loss = -21.581016540527344\n",
      "step = 2360: loss = -13.41650390625\n",
      "step = 2365: loss = -16.414390563964844\n",
      "step = 2370: loss = -16.888721466064453\n",
      "step = 2375: loss = -17.935888290405273\n",
      "step = 2380: loss = -18.33527183532715\n",
      "step = 2385: loss = -16.407039642333984\n",
      "step = 2390: loss = -16.981792449951172\n",
      "step = 2395: loss = 0.9665842056274414\n",
      "step = 2400: loss = -22.011310577392578\n",
      "step = 2400: Average Return = 0.0\n",
      " 0: 8 -  0: 8 -  0: 7 -  0: 9 -  0:11 -  0:10 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2405: loss = -15.730269432067871\n",
      "step = 2410: loss = -18.530986785888672\n",
      "step = 2415: loss = -16.913631439208984\n",
      "step = 2420: loss = -19.88115119934082\n",
      "step = 2425: loss = -21.411705017089844\n",
      "step = 2430: loss = -22.21029281616211\n",
      "step = 2435: loss = -19.858089447021484\n",
      "step = 2440: loss = -19.944990158081055\n",
      "step = 2445: loss = -16.134735107421875\n",
      "step = 2450: loss = -10.1004056930542\n",
      "step = 2455: loss = -24.707550048828125\n",
      "step = 2460: loss = -18.676029205322266\n",
      "step = 2465: loss = -21.23392677307129\n",
      "step = 2470: loss = -24.541854858398438\n",
      "step = 2475: loss = -18.194721221923828\n",
      "step = 2480: loss = -22.54592514038086\n",
      "step = 2485: loss = -17.651397705078125\n",
      "step = 2490: loss = -21.841293334960938\n",
      "step = 2495: loss = -22.803016662597656\n",
      "step = 2500: loss = -21.417985916137695\n",
      "step = 2500: Average Return = 1.0\n",
      " 0: 7 -  0: 8 -  0: 6 -  0: 9 -  0:10 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2505: loss = -20.91162109375\n",
      "step = 2510: loss = -16.02801513671875\n",
      "step = 2515: loss = -21.704299926757812\n",
      "step = 2520: loss = -19.149614334106445\n",
      "step = 2525: loss = 1.5053529739379883\n",
      "step = 2530: loss = -15.582582473754883\n",
      "step = 2535: loss = -20.72665786743164\n",
      "step = 2540: loss = -21.49768829345703\n",
      "step = 2545: loss = -20.016685485839844\n",
      "step = 2550: loss = -26.78685760498047\n",
      "step = 2555: loss = -22.36969566345215\n",
      "step = 2560: loss = -16.76595687866211\n",
      "step = 2565: loss = -19.341629028320312\n",
      "step = 2570: loss = -19.523502349853516\n",
      "step = 2575: loss = -21.040367126464844\n",
      "step = 2580: loss = -22.22225570678711\n",
      "step = 2585: loss = -19.716259002685547\n",
      "step = 2590: loss = -23.846065521240234\n",
      "step = 2595: loss = -21.309877395629883\n",
      "step = 2600: loss = 0.8820009231567383\n",
      "step = 2600: Average Return = 1.0\n",
      " 0: 6 -  0: 7 -  0: 5 -  0: 9 -  0: 9 -  0: 8 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2605: loss = -21.70049285888672\n",
      "step = 2610: loss = -23.40579605102539\n",
      "step = 2615: loss = -19.269935607910156\n",
      "step = 2620: loss = -21.187788009643555\n",
      "step = 2625: loss = -20.610694885253906\n",
      "step = 2630: loss = -21.429805755615234\n",
      "step = 2635: loss = -17.778074264526367\n",
      "step = 2640: loss = -20.69438362121582\n",
      "step = 2645: loss = -22.21623992919922\n",
      "step = 2650: loss = -20.97149658203125\n",
      "step = 2655: loss = -20.6948184967041\n",
      "step = 2660: loss = -23.49848175048828\n",
      "step = 2665: loss = -21.61100959777832\n",
      "step = 2670: loss = -21.661102294921875\n",
      "step = 2675: loss = -26.438905715942383\n",
      "step = 2680: loss = -21.223873138427734\n",
      "step = 2685: loss = -20.651012420654297\n",
      "step = 2690: loss = -20.177730560302734\n",
      "step = 2695: loss = -23.705554962158203\n",
      "step = 2700: loss = -21.848419189453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 2700: Average Return = 0.0\n",
      " 0: 6 -  0: 6 -  0: 5 -  0: 8 -  0: 8 -  0: 8 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2705: loss = -26.064716339111328\n",
      "step = 2710: loss = -26.250362396240234\n",
      "step = 2715: loss = -22.63054656982422\n",
      "step = 2720: loss = -24.274372100830078\n",
      "step = 2725: loss = -21.971303939819336\n",
      "step = 2730: loss = -23.242660522460938\n",
      "step = 2735: loss = -22.266937255859375\n",
      "step = 2740: loss = -20.78853988647461\n",
      "step = 2745: loss = -24.063283920288086\n",
      "step = 2750: loss = -21.28596305847168\n",
      "step = 2755: loss = -25.021053314208984\n",
      "step = 2760: loss = -23.479923248291016\n",
      "step = 2765: loss = -24.727235794067383\n",
      "step = 2770: loss = -20.35879898071289\n",
      "step = 2775: loss = -24.975799560546875\n",
      "step = 2780: loss = -24.562692642211914\n",
      "step = 2785: loss = -27.056167602539062\n",
      "step = 2790: loss = -25.73701286315918\n",
      "step = 2795: loss = -24.577556610107422\n",
      "step = 2800: loss = -27.78976821899414\n",
      "step = 2800: Average Return = 0.0\n",
      " 0: 6 -  0: 6 -  0: 5 -  0: 7 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2805: loss = -24.4831600189209\n",
      "step = 2810: loss = -18.532581329345703\n",
      "step = 2815: loss = -19.050987243652344\n",
      "step = 2820: loss = -23.364208221435547\n",
      "step = 2825: loss = -21.697154998779297\n",
      "step = 2830: loss = -24.086620330810547\n",
      "step = 2835: loss = -23.444869995117188\n",
      "step = 2840: loss = -23.891714096069336\n",
      "step = 2845: loss = -23.96957015991211\n",
      "step = 2850: loss = -19.39307975769043\n",
      "step = 2855: loss = -24.301448822021484\n",
      "step = 2860: loss = -24.618885040283203\n",
      "step = 2865: loss = -23.489913940429688\n",
      "step = 2870: loss = -23.99859046936035\n",
      "step = 2875: loss = -24.4168701171875\n",
      "step = 2880: loss = -20.009140014648438\n",
      "step = 2885: loss = -25.0900821685791\n",
      "step = 2890: loss = -27.652324676513672\n",
      "step = 2895: loss = -29.373188018798828\n",
      "step = 2900: loss = -23.518354415893555\n",
      "step = 2900: Average Return = 0.0\n",
      " 0: 6 -  0: 6 -  0: 4 -  0: 7 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 2905: loss = -26.176570892333984\n",
      "step = 2910: loss = -24.418642044067383\n",
      "step = 2915: loss = -7.753711700439453\n",
      "step = 2920: loss = -24.504512786865234\n",
      "step = 2925: loss = -27.458759307861328\n",
      "step = 2930: loss = -29.11947250366211\n",
      "step = 2935: loss = -24.370582580566406\n",
      "step = 2940: loss = -24.103652954101562\n",
      "step = 2945: loss = -24.053363800048828\n",
      "step = 2950: loss = -24.476173400878906\n",
      "step = 2955: loss = -22.09349822998047\n",
      "step = 2960: loss = -26.440814971923828\n",
      "step = 2965: loss = -23.60280990600586\n",
      "step = 2970: loss = -23.087900161743164\n",
      "step = 2975: loss = -23.431507110595703\n",
      "step = 2980: loss = -23.34381866455078\n",
      "step = 2985: loss = -27.979339599609375\n",
      "step = 2990: loss = -28.41126823425293\n",
      "step = 2995: loss = -23.4552001953125\n",
      "step = 3000: loss = -23.246713638305664\n",
      "step = 3000: Average Return = 0.0\n",
      " 0: 6 -  0: 6 -  0: 4 -  0: 6 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3005: loss = -24.588558197021484\n",
      "step = 3010: loss = -24.611225128173828\n",
      "step = 3015: loss = -1.7463502883911133\n",
      "step = 3020: loss = -23.442554473876953\n",
      "step = 3025: loss = -23.92873764038086\n",
      "step = 3030: loss = -24.157115936279297\n",
      "step = 3035: loss = -25.82996368408203\n",
      "step = 3040: loss = -9.486492156982422\n",
      "step = 3045: loss = -22.804821014404297\n",
      "step = 3050: loss = -23.601688385009766\n",
      "step = 3055: loss = -8.509357452392578\n",
      "step = 3060: loss = -22.820972442626953\n",
      "step = 3065: loss = -26.530120849609375\n",
      "step = 3070: loss = -28.43337059020996\n",
      "step = 3075: loss = -26.488039016723633\n",
      "step = 3080: loss = -21.984254837036133\n",
      "step = 3085: loss = -25.193470001220703\n",
      "step = 3090: loss = -22.65509796142578\n",
      "step = 3095: loss = -25.981414794921875\n",
      "step = 3100: loss = -26.782894134521484\n",
      "step = 3100: Average Return = 0.0\n",
      " 0: 6 -  0: 6 -  0: 4 -  0: 6 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3105: loss = -25.633502960205078\n",
      "step = 3110: loss = -26.13549041748047\n",
      "step = 3115: loss = -25.271625518798828\n",
      "step = 3120: loss = -26.306047439575195\n",
      "step = 3125: loss = -24.620555877685547\n",
      "step = 3130: loss = -25.504478454589844\n",
      "step = 3135: loss = -24.576385498046875\n",
      "step = 3140: loss = -23.67818832397461\n",
      "step = 3145: loss = -25.58066177368164\n",
      "step = 3150: loss = -25.450096130371094\n",
      "step = 3155: loss = -28.72768783569336\n",
      "step = 3160: loss = -24.45060920715332\n",
      "step = 3165: loss = -23.775663375854492\n",
      "step = 3170: loss = -26.239269256591797\n",
      "step = 3175: loss = -29.868412017822266\n",
      "step = 3180: loss = -23.525218963623047\n",
      "step = 3185: loss = -27.553382873535156\n",
      "step = 3190: loss = -25.173002243041992\n",
      "step = 3195: loss = -6.978704452514648\n",
      "step = 3200: loss = -6.617104530334473\n",
      "step = 3200: Average Return = 0.0\n",
      " 0: 6 -  0: 6 -  0: 4 -  0: 6 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3205: loss = -24.85319709777832\n",
      "step = 3210: loss = -21.864822387695312\n",
      "step = 3215: loss = -27.017391204833984\n",
      "step = 3220: loss = -24.9912052154541\n",
      "step = 3225: loss = -24.014760971069336\n",
      "step = 3230: loss = -26.973127365112305\n",
      "step = 3235: loss = -27.59124755859375\n",
      "step = 3240: loss = -24.804515838623047\n",
      "step = 3245: loss = -22.53139305114746\n",
      "step = 3250: loss = -25.2889404296875\n",
      "step = 3255: loss = -23.393299102783203\n",
      "step = 3260: loss = -25.57140350341797\n",
      "step = 3265: loss = -26.132335662841797\n",
      "step = 3270: loss = -24.54743766784668\n",
      "step = 3275: loss = -29.126087188720703\n",
      "step = 3280: loss = -26.348976135253906\n",
      "step = 3285: loss = -24.496131896972656\n",
      "step = 3290: loss = -23.468894958496094\n",
      "step = 3295: loss = -27.802526473999023\n",
      "step = 3300: loss = -26.39716339111328\n",
      "step = 3300: Average Return = 1.0\n",
      " 0: 6 -  0: 7 -  0: 4 -  0: 5 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3305: loss = -6.639032363891602\n",
      "step = 3310: loss = -25.52601432800293\n",
      "step = 3315: loss = -25.94879722595215\n",
      "step = 3320: loss = -24.253860473632812\n",
      "step = 3325: loss = -25.253746032714844\n",
      "step = 3330: loss = -28.849437713623047\n",
      "step = 3335: loss = -28.15337562561035\n",
      "step = 3340: loss = -26.124303817749023\n",
      "step = 3345: loss = -24.52835464477539\n",
      "step = 3350: loss = -26.25023651123047\n",
      "step = 3355: loss = -27.053085327148438\n",
      "step = 3360: loss = -26.670917510986328\n",
      "step = 3365: loss = -26.22144889831543\n",
      "step = 3370: loss = -26.75431251525879\n",
      "step = 3375: loss = -25.280614852905273\n",
      "step = 3380: loss = -27.91834259033203\n",
      "step = 3385: loss = -26.52362060546875\n",
      "step = 3390: loss = -25.46221160888672\n",
      "step = 3395: loss = -26.622215270996094\n",
      "step = 3400: loss = -24.4609375\n",
      "step = 3400: Average Return = 1.0\n",
      " 0: 6 -  0: 8 -  0: 4 -  0: 5 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3405: loss = -28.281360626220703\n",
      "step = 3410: loss = -24.293621063232422\n",
      "step = 3415: loss = -27.886547088623047\n",
      "step = 3420: loss = -26.297460556030273\n",
      "step = 3425: loss = -24.229206085205078\n",
      "step = 3430: loss = -26.877119064331055\n",
      "step = 3435: loss = -28.732025146484375\n",
      "step = 3440: loss = -26.837310791015625\n",
      "step = 3445: loss = -27.089717864990234\n",
      "step = 3450: loss = -27.509765625\n",
      "step = 3455: loss = -12.24867057800293\n",
      "step = 3460: loss = -27.784120559692383\n",
      "step = 3465: loss = -27.716005325317383\n",
      "step = 3470: loss = -26.321640014648438\n",
      "step = 3475: loss = -24.843107223510742\n",
      "step = 3480: loss = -28.518123626708984\n",
      "step = 3485: loss = -27.937583923339844\n",
      "step = 3490: loss = -30.599145889282227\n",
      "step = 3495: loss = -26.352825164794922\n",
      "step = 3500: loss = -27.25356674194336\n",
      "step = 3500: Average Return = 1.0\n",
      " 0: 6 -  0: 8 -  0: 4 -  0: 5 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3505: loss = -26.558544158935547\n",
      "step = 3510: loss = -27.4398193359375\n",
      "step = 3515: loss = -28.404312133789062\n",
      "step = 3520: loss = -30.932035446166992\n",
      "step = 3525: loss = -27.198123931884766\n",
      "step = 3530: loss = -26.51800537109375\n",
      "step = 3535: loss = -26.102094650268555\n",
      "step = 3540: loss = -8.510992050170898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 3545: loss = -27.459712982177734\n",
      "step = 3550: loss = -22.901996612548828\n",
      "step = 3555: loss = -27.70500946044922\n",
      "step = 3560: loss = -25.658435821533203\n",
      "step = 3565: loss = -28.125730514526367\n",
      "step = 3570: loss = -25.829429626464844\n",
      "step = 3575: loss = -24.843521118164062\n",
      "step = 3580: loss = -29.597179412841797\n",
      "step = 3585: loss = -28.084732055664062\n",
      "step = 3590: loss = -9.680445671081543\n",
      "step = 3595: loss = -26.80937385559082\n",
      "step = 3600: loss = -25.810041427612305\n",
      "step = 3600: Average Return = 1.0\n",
      " 0: 6 -  0: 7 -  0: 4 -  0: 5 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3605: loss = -29.56603240966797\n",
      "step = 3610: loss = -27.66031265258789\n",
      "step = 3615: loss = -27.92970085144043\n",
      "step = 3620: loss = -26.371383666992188\n",
      "step = 3625: loss = -28.233675003051758\n",
      "step = 3630: loss = -27.069744110107422\n",
      "step = 3635: loss = -27.50440216064453\n",
      "step = 3640: loss = -27.505413055419922\n",
      "step = 3645: loss = -28.489791870117188\n",
      "step = 3650: loss = -29.44025421142578\n",
      "step = 3655: loss = -29.289443969726562\n",
      "step = 3660: loss = -28.038284301757812\n",
      "step = 3665: loss = -27.65382957458496\n",
      "step = 3670: loss = -27.65351676940918\n",
      "step = 3675: loss = -31.565147399902344\n",
      "step = 3680: loss = -29.875045776367188\n",
      "step = 3685: loss = -29.16807746887207\n",
      "step = 3690: loss = -29.682960510253906\n",
      "step = 3695: loss = -25.799795150756836\n",
      "step = 3700: loss = -27.32814598083496\n",
      "step = 3700: Average Return = 1.0\n",
      " 0: 5 -  0: 7 -  0: 4 -  0: 5 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3705: loss = -27.789649963378906\n",
      "step = 3710: loss = -28.39130210876465\n",
      "step = 3715: loss = -29.604190826416016\n",
      "step = 3720: loss = -29.41979217529297\n",
      "step = 3725: loss = -27.048686981201172\n",
      "step = 3730: loss = -27.710540771484375\n",
      "step = 3735: loss = -28.731698989868164\n",
      "step = 3740: loss = -29.823883056640625\n",
      "step = 3745: loss = -27.356096267700195\n",
      "step = 3750: loss = -29.158588409423828\n",
      "step = 3755: loss = -28.498271942138672\n",
      "step = 3760: loss = -28.2933406829834\n",
      "step = 3765: loss = -27.19630241394043\n",
      "step = 3770: loss = -28.540416717529297\n",
      "step = 3775: loss = -27.490550994873047\n",
      "step = 3780: loss = -32.39126205444336\n",
      "step = 3785: loss = -28.438880920410156\n",
      "step = 3790: loss = -27.819442749023438\n",
      "step = 3795: loss = -29.67900848388672\n",
      "step = 3800: loss = -27.39992332458496\n",
      "step = 3800: Average Return = 1.0\n",
      " 0: 5 -  0: 8 -  0: 4 -  0: 5 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3805: loss = -28.425617218017578\n",
      "step = 3810: loss = -29.902130126953125\n",
      "step = 3815: loss = -28.154123306274414\n",
      "step = 3820: loss = -28.610733032226562\n",
      "step = 3825: loss = -28.123291015625\n",
      "step = 3830: loss = -30.333419799804688\n",
      "step = 3835: loss = -29.79891586303711\n",
      "step = 3840: loss = -28.4966983795166\n",
      "step = 3845: loss = -30.40854835510254\n",
      "step = 3850: loss = -10.831696510314941\n",
      "step = 3855: loss = -30.610593795776367\n",
      "step = 3860: loss = -31.093486785888672\n",
      "step = 3865: loss = -11.998355865478516\n",
      "step = 3870: loss = -30.058135986328125\n",
      "step = 3875: loss = -27.99032211303711\n",
      "step = 3880: loss = -29.825193405151367\n",
      "step = 3885: loss = -26.816444396972656\n",
      "step = 3890: loss = -30.174049377441406\n",
      "step = 3895: loss = -27.056835174560547\n",
      "step = 3900: loss = -10.899763107299805\n",
      "step = 3900: Average Return = 1.0\n",
      " 0: 5 -  0: 8 -  0: 4 -  0: 6 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 3905: loss = -27.01636505126953\n",
      "step = 3910: loss = -28.973556518554688\n",
      "step = 3915: loss = -30.83428192138672\n",
      "step = 3920: loss = -30.502174377441406\n",
      "step = 3925: loss = -30.620059967041016\n",
      "step = 3930: loss = -30.236167907714844\n",
      "step = 3935: loss = -29.804765701293945\n",
      "step = 3940: loss = -20.798202514648438\n",
      "step = 3945: loss = -28.182479858398438\n",
      "step = 3950: loss = -29.72390365600586\n",
      "step = 3955: loss = -29.80207061767578\n",
      "step = 3960: loss = -29.909814834594727\n",
      "step = 3965: loss = -28.21157455444336\n",
      "step = 3970: loss = -30.493558883666992\n",
      "step = 3975: loss = -29.218994140625\n",
      "step = 3980: loss = -29.20379066467285\n",
      "step = 3985: loss = -28.27699089050293\n",
      "step = 3990: loss = -31.023914337158203\n",
      "step = 3995: loss = -29.879131317138672\n",
      "step = 4000: loss = -31.46728515625\n",
      "step = 4000: Average Return = 1.0\n",
      " 0: 5 -  0: 8 -  0: 4 -  0: 6 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4005: loss = -32.00211715698242\n",
      "step = 4010: loss = -28.420917510986328\n",
      "step = 4015: loss = -30.48355484008789\n",
      "step = 4020: loss = -30.417465209960938\n",
      "step = 4025: loss = -32.79020309448242\n",
      "step = 4030: loss = -29.526762008666992\n",
      "step = 4035: loss = -32.217323303222656\n",
      "step = 4040: loss = -15.522476196289062\n",
      "step = 4045: loss = -30.163097381591797\n",
      "step = 4050: loss = -13.608415603637695\n",
      "step = 4055: loss = -33.37409973144531\n",
      "step = 4060: loss = -30.52344512939453\n",
      "step = 4065: loss = -29.284706115722656\n",
      "step = 4070: loss = -10.521516799926758\n",
      "step = 4075: loss = -29.05544662475586\n",
      "step = 4080: loss = -33.429542541503906\n",
      "step = 4085: loss = -31.53990364074707\n",
      "step = 4090: loss = -31.472362518310547\n",
      "step = 4095: loss = -30.77255630493164\n",
      "step = 4100: loss = -26.90349578857422\n",
      "step = 4100: Average Return = 1.0\n",
      " 0: 5 -  0: 8 -  0: 4 -  0: 6 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4105: loss = -32.79225158691406\n",
      "step = 4110: loss = -29.872495651245117\n",
      "step = 4115: loss = -28.133949279785156\n",
      "step = 4120: loss = -31.45828628540039\n",
      "step = 4125: loss = -31.664403915405273\n",
      "step = 4130: loss = -30.39333724975586\n",
      "step = 4135: loss = -13.02957534790039\n",
      "step = 4140: loss = -30.572616577148438\n",
      "step = 4145: loss = -30.732179641723633\n",
      "step = 4150: loss = -33.35384750366211\n",
      "step = 4155: loss = -31.2134952545166\n",
      "step = 4160: loss = -32.240928649902344\n",
      "step = 4165: loss = -28.2742977142334\n",
      "step = 4170: loss = -32.4711799621582\n",
      "step = 4175: loss = -30.661142349243164\n",
      "step = 4180: loss = -33.53052520751953\n",
      "step = 4185: loss = -30.410076141357422\n",
      "step = 4190: loss = -30.111547470092773\n",
      "step = 4195: loss = -32.18759536743164\n",
      "step = 4200: loss = -29.16569709777832\n",
      "step = 4200: Average Return = 1.0\n",
      " 0: 4 -  0: 9 -  0: 4 -  0: 6 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4205: loss = -32.07697296142578\n",
      "step = 4210: loss = -30.724794387817383\n",
      "step = 4215: loss = -31.464265823364258\n",
      "step = 4220: loss = -30.156475067138672\n",
      "step = 4225: loss = -30.421234130859375\n",
      "step = 4230: loss = -31.744503021240234\n",
      "step = 4235: loss = -16.444028854370117\n",
      "step = 4240: loss = -31.291799545288086\n",
      "step = 4245: loss = -32.054466247558594\n",
      "step = 4250: loss = -29.634201049804688\n",
      "step = 4255: loss = -31.84543228149414\n",
      "step = 4260: loss = -31.694496154785156\n",
      "step = 4265: loss = -33.365901947021484\n",
      "step = 4270: loss = -32.457618713378906\n",
      "step = 4275: loss = -31.002832412719727\n",
      "step = 4280: loss = -31.32913589477539\n",
      "step = 4285: loss = -30.284963607788086\n",
      "step = 4290: loss = -31.20293426513672\n",
      "step = 4295: loss = -33.62329864501953\n",
      "step = 4300: loss = -31.586017608642578\n",
      "step = 4300: Average Return = 1.0\n",
      " 0: 4 -  0: 9 -  0: 4 -  0: 6 -  0: 8 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4305: loss = -33.29372787475586\n",
      "step = 4310: loss = -32.8743896484375\n",
      "step = 4315: loss = -31.28949737548828\n",
      "step = 4320: loss = -33.119544982910156\n",
      "step = 4325: loss = -30.0555362701416\n",
      "step = 4330: loss = -32.44069290161133\n",
      "step = 4335: loss = -32.53422927856445\n",
      "step = 4340: loss = -21.539663314819336\n",
      "step = 4345: loss = -32.2310676574707\n",
      "step = 4350: loss = -35.33088684082031\n",
      "step = 4355: loss = -31.58883285522461\n",
      "step = 4360: loss = -29.651275634765625\n",
      "step = 4365: loss = -31.83812141418457\n",
      "step = 4370: loss = -31.62546730041504\n",
      "step = 4375: loss = -31.130929946899414\n",
      "step = 4380: loss = -30.903823852539062\n",
      "step = 4385: loss = -33.11417770385742\n",
      "step = 4390: loss = -31.41518783569336\n",
      "step = 4395: loss = -32.09513854980469\n",
      "step = 4400: loss = -33.55186462402344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 4400: Average Return = 1.0\n",
      " 0: 4 -  0: 9 -  0: 4 -  0: 6 -  0: 8 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4405: loss = -31.073244094848633\n",
      "step = 4410: loss = -29.593250274658203\n",
      "step = 4415: loss = -15.19007682800293\n",
      "step = 4420: loss = -32.391578674316406\n",
      "step = 4425: loss = -15.441265106201172\n",
      "step = 4430: loss = -32.79753875732422\n",
      "step = 4435: loss = -32.49957275390625\n",
      "step = 4440: loss = -33.39134979248047\n",
      "step = 4445: loss = -32.5627555847168\n",
      "step = 4450: loss = -31.9293155670166\n",
      "step = 4455: loss = -35.670623779296875\n",
      "step = 4460: loss = -33.391395568847656\n",
      "step = 4465: loss = -33.7978630065918\n",
      "step = 4470: loss = -32.93018341064453\n",
      "step = 4475: loss = -34.97431182861328\n",
      "step = 4480: loss = -31.65304183959961\n",
      "step = 4485: loss = -32.55483627319336\n",
      "step = 4490: loss = -32.47981643676758\n",
      "step = 4495: loss = -24.45456314086914\n",
      "step = 4500: loss = -32.24607849121094\n",
      "step = 4500: Average Return = 1.0\n",
      " 0: 4 -  0: 9 -  0: 4 -  0: 6 -  0: 8 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4505: loss = -31.26146697998047\n",
      "step = 4510: loss = -35.62390899658203\n",
      "step = 4515: loss = -33.72566604614258\n",
      "step = 4520: loss = -32.322105407714844\n",
      "step = 4525: loss = -32.83120346069336\n",
      "step = 4530: loss = -33.304161071777344\n",
      "step = 4535: loss = -34.02077102661133\n",
      "step = 4540: loss = -33.377655029296875\n",
      "step = 4545: loss = -22.758729934692383\n",
      "step = 4550: loss = -34.39037322998047\n",
      "step = 4555: loss = -34.23722839355469\n",
      "step = 4560: loss = -33.293052673339844\n",
      "step = 4565: loss = -34.023765563964844\n",
      "step = 4570: loss = -31.068031311035156\n",
      "step = 4575: loss = -33.93506622314453\n",
      "step = 4580: loss = -32.77730178833008\n",
      "step = 4585: loss = -16.92620277404785\n",
      "step = 4590: loss = -18.84292984008789\n",
      "step = 4595: loss = -33.356544494628906\n",
      "step = 4600: loss = -33.21256637573242\n",
      "step = 4600: Average Return = 1.0\n",
      " 0: 4 -  0: 8 -  0: 4 -  0: 7 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4605: loss = -34.84306335449219\n",
      "step = 4610: loss = -33.96078872680664\n",
      "step = 4615: loss = -34.774715423583984\n",
      "step = 4620: loss = -33.83006286621094\n",
      "step = 4625: loss = -33.123653411865234\n",
      "step = 4630: loss = -30.958660125732422\n",
      "step = 4635: loss = -18.534486770629883\n",
      "step = 4640: loss = -34.16138458251953\n",
      "step = 4645: loss = -32.33893585205078\n",
      "step = 4650: loss = -16.283388137817383\n",
      "step = 4655: loss = -33.526390075683594\n",
      "step = 4660: loss = -36.00410461425781\n",
      "step = 4665: loss = -35.11076354980469\n",
      "step = 4670: loss = -33.6199951171875\n",
      "step = 4675: loss = -34.592185974121094\n",
      "step = 4680: loss = -33.568477630615234\n",
      "step = 4685: loss = -32.54814147949219\n",
      "step = 4690: loss = -33.232460021972656\n",
      "step = 4695: loss = -32.653587341308594\n",
      "step = 4700: loss = -34.6983642578125\n",
      "step = 4700: Average Return = 1.0\n",
      " 0: 4 -  0: 8 -  0: 4 -  0: 7 -  0: 8 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4705: loss = -34.09638595581055\n",
      "step = 4710: loss = -33.632164001464844\n",
      "step = 4715: loss = -33.80805206298828\n",
      "step = 4720: loss = -34.52308654785156\n",
      "step = 4725: loss = -34.13420867919922\n",
      "step = 4730: loss = -33.34141540527344\n",
      "step = 4735: loss = -30.982112884521484\n",
      "step = 4740: loss = -32.32936096191406\n",
      "step = 4745: loss = -33.95578384399414\n",
      "step = 4750: loss = -34.04705810546875\n",
      "step = 4755: loss = -36.16946029663086\n",
      "step = 4760: loss = -34.451778411865234\n",
      "step = 4765: loss = -34.023765563964844\n",
      "step = 4770: loss = -36.57573318481445\n",
      "step = 4775: loss = -34.7684326171875\n",
      "step = 4780: loss = -35.0695915222168\n",
      "step = 4785: loss = -33.67905807495117\n",
      "step = 4790: loss = -35.3010139465332\n",
      "step = 4795: loss = -35.66093444824219\n",
      "step = 4800: loss = -35.33843231201172\n",
      "step = 4800: Average Return = 1.0\n",
      " 0: 4 -  0: 9 -  0: 5 -  0: 7 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4805: loss = -35.91803741455078\n",
      "step = 4810: loss = -33.46895217895508\n",
      "step = 4815: loss = -37.19572830200195\n",
      "step = 4820: loss = -34.363224029541016\n",
      "step = 4825: loss = -34.569976806640625\n",
      "step = 4830: loss = -36.838409423828125\n",
      "step = 4835: loss = -35.61679458618164\n",
      "step = 4840: loss = -34.65654754638672\n",
      "step = 4845: loss = -36.45059585571289\n",
      "step = 4850: loss = -37.42994689941406\n",
      "step = 4855: loss = -35.689422607421875\n",
      "step = 4860: loss = -36.76420593261719\n",
      "step = 4865: loss = -36.1192626953125\n",
      "step = 4870: loss = -35.389137268066406\n",
      "step = 4875: loss = -36.51091766357422\n",
      "step = 4880: loss = -33.400543212890625\n",
      "step = 4885: loss = -34.315643310546875\n",
      "step = 4890: loss = -38.2620849609375\n",
      "step = 4895: loss = -37.343406677246094\n",
      "step = 4900: loss = -36.764286041259766\n",
      "step = 4900: Average Return = 1.0\n",
      " 0: 4 -  0: 8 -  0: 5 -  0: 7 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 4905: loss = -36.582191467285156\n",
      "step = 4910: loss = -36.308345794677734\n",
      "step = 4915: loss = -34.567291259765625\n",
      "step = 4920: loss = -35.76405334472656\n",
      "step = 4925: loss = -36.87279510498047\n",
      "step = 4930: loss = -37.137969970703125\n",
      "step = 4935: loss = -36.045875549316406\n",
      "step = 4940: loss = -36.14356231689453\n",
      "step = 4945: loss = -37.26593017578125\n",
      "step = 4950: loss = -39.14406967163086\n",
      "step = 4955: loss = -36.243099212646484\n",
      "step = 4960: loss = -37.91770935058594\n",
      "step = 4965: loss = -36.65070343017578\n",
      "step = 4970: loss = -33.686790466308594\n",
      "step = 4975: loss = -36.30443572998047\n",
      "step = 4980: loss = -37.384307861328125\n",
      "step = 4985: loss = -36.0640869140625\n",
      "step = 4990: loss = -34.293846130371094\n",
      "step = 4995: loss = -33.824623107910156\n",
      "step = 5000: loss = -37.25804138183594\n",
      "step = 5000: Average Return = 1.0\n",
      " 0: 3 -  0: 9 -  0: 4 -  0: 9 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5005: loss = -35.71818161010742\n",
      "step = 5010: loss = -35.42195129394531\n",
      "step = 5015: loss = -37.53898620605469\n",
      "step = 5020: loss = -36.86967468261719\n",
      "step = 5025: loss = -36.82606506347656\n",
      "step = 5030: loss = -36.68379211425781\n",
      "step = 5035: loss = -35.478187561035156\n",
      "step = 5040: loss = -35.61856460571289\n",
      "step = 5045: loss = -38.44740295410156\n",
      "step = 5050: loss = -35.735816955566406\n",
      "step = 5055: loss = -36.85095977783203\n",
      "step = 5060: loss = -37.71367645263672\n",
      "step = 5065: loss = -37.50080871582031\n",
      "step = 5070: loss = -37.53797149658203\n",
      "step = 5075: loss = -36.66819381713867\n",
      "step = 5080: loss = -36.391014099121094\n",
      "step = 5085: loss = -36.830596923828125\n",
      "step = 5090: loss = -36.865081787109375\n",
      "step = 5095: loss = -37.41984558105469\n",
      "step = 5100: loss = -38.002254486083984\n",
      "step = 5100: Average Return = 1.0\n",
      " 0: 3 -  0: 8 -  0: 4 -  0:12 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5105: loss = -35.54039001464844\n",
      "step = 5110: loss = -36.084102630615234\n",
      "step = 5115: loss = -35.679473876953125\n",
      "step = 5120: loss = -37.07781219482422\n",
      "step = 5125: loss = -35.22980499267578\n",
      "step = 5130: loss = -37.12944030761719\n",
      "step = 5135: loss = -37.567405700683594\n",
      "step = 5140: loss = -36.18865966796875\n",
      "step = 5145: loss = -36.84696578979492\n",
      "step = 5150: loss = -20.748638153076172\n",
      "step = 5155: loss = -37.431156158447266\n",
      "step = 5160: loss = -38.367881774902344\n",
      "step = 5165: loss = -36.40167999267578\n",
      "step = 5170: loss = -20.8670711517334\n",
      "step = 5175: loss = -37.95998001098633\n",
      "step = 5180: loss = -36.514060974121094\n",
      "step = 5185: loss = -37.432106018066406\n",
      "step = 5190: loss = -38.351619720458984\n",
      "step = 5195: loss = -37.41918182373047\n",
      "step = 5200: loss = -36.379295349121094\n",
      "step = 5200: Average Return = 1.0\n",
      " 0: 3 -  0: 8 -  0: 4 -  0: 9 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5205: loss = -37.57955551147461\n",
      "step = 5210: loss = -38.018062591552734\n",
      "step = 5215: loss = -37.74625778198242\n",
      "step = 5220: loss = -35.408668518066406\n",
      "step = 5225: loss = -38.184349060058594\n",
      "step = 5230: loss = -35.858306884765625\n",
      "step = 5235: loss = -37.091400146484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5240: loss = -36.93840789794922\n",
      "step = 5245: loss = -38.09552764892578\n",
      "step = 5250: loss = -39.1258544921875\n",
      "step = 5255: loss = -27.22848892211914\n",
      "step = 5260: loss = -38.387569427490234\n",
      "step = 5265: loss = -37.75454330444336\n",
      "step = 5270: loss = -36.988014221191406\n",
      "step = 5275: loss = -37.75649642944336\n",
      "step = 5280: loss = -37.97779083251953\n",
      "step = 5285: loss = -38.347957611083984\n",
      "step = 5290: loss = -37.88997268676758\n",
      "step = 5295: loss = -37.3929443359375\n",
      "step = 5300: loss = -37.812095642089844\n",
      "step = 5300: Average Return = 1.0\n",
      " 0: 3 -  0: 7 -  0: 5 -  0:14 -  0: 7 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5305: loss = -38.22441864013672\n",
      "step = 5310: loss = -35.39101028442383\n",
      "step = 5315: loss = -36.42237091064453\n",
      "step = 5320: loss = -18.63270378112793\n",
      "step = 5325: loss = -38.611915588378906\n",
      "step = 5330: loss = -36.9307746887207\n",
      "step = 5335: loss = -35.213035583496094\n",
      "step = 5340: loss = -38.803077697753906\n",
      "step = 5345: loss = -36.58341979980469\n",
      "step = 5350: loss = -35.92595672607422\n",
      "step = 5355: loss = -37.37744903564453\n",
      "step = 5360: loss = -36.95845413208008\n",
      "step = 5365: loss = -37.92108917236328\n",
      "step = 5370: loss = -19.53672218322754\n",
      "step = 5375: loss = -35.61185836791992\n",
      "step = 5380: loss = -35.00979232788086\n",
      "step = 5385: loss = -35.67290496826172\n",
      "step = 5390: loss = -36.57481384277344\n",
      "step = 5395: loss = -36.36131286621094\n",
      "step = 5400: loss = -33.01503372192383\n",
      "step = 5400: Average Return = 1.0\n",
      " 0: 2 -  0: 5 -  0: 3 -  0:17 -  0: 5 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5405: loss = -37.92658615112305\n",
      "step = 5410: loss = -35.333763122558594\n",
      "step = 5415: loss = -37.3495979309082\n",
      "step = 5420: loss = -31.376018524169922\n",
      "step = 5425: loss = -32.834320068359375\n",
      "step = 5430: loss = -36.13697052001953\n",
      "step = 5435: loss = -33.851409912109375\n",
      "step = 5440: loss = -34.409385681152344\n",
      "step = 5445: loss = -34.048641204833984\n",
      "step = 5450: loss = -35.884151458740234\n",
      "step = 5455: loss = -36.76303482055664\n",
      "step = 5460: loss = -17.04942512512207\n",
      "step = 5465: loss = -35.46070098876953\n",
      "step = 5470: loss = -33.71741485595703\n",
      "step = 5475: loss = -36.36207962036133\n",
      "step = 5480: loss = -33.19253158569336\n",
      "step = 5485: loss = -35.21797180175781\n",
      "step = 5490: loss = -35.87333679199219\n",
      "step = 5495: loss = -35.535072326660156\n",
      "step = 5500: loss = -24.127248764038086\n",
      "step = 5500: Average Return = 1.0\n",
      " 0: 1 -  0: 5 -  0: 3 -  0:18 -  0: 5 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5505: loss = -17.521825790405273\n",
      "step = 5510: loss = -34.67871856689453\n",
      "step = 5515: loss = -34.613739013671875\n",
      "step = 5520: loss = -35.17237091064453\n",
      "step = 5525: loss = -35.22515869140625\n",
      "step = 5530: loss = -35.83631134033203\n",
      "step = 5535: loss = -35.89363479614258\n",
      "step = 5540: loss = -33.94194030761719\n",
      "step = 5545: loss = -34.88561248779297\n",
      "step = 5550: loss = -38.27009582519531\n",
      "step = 5555: loss = -34.36958312988281\n",
      "step = 5560: loss = -37.49589920043945\n",
      "step = 5565: loss = -32.404815673828125\n",
      "step = 5570: loss = -34.89865493774414\n",
      "step = 5575: loss = -35.87249755859375\n",
      "step = 5580: loss = -35.20660400390625\n",
      "step = 5585: loss = -38.424766540527344\n",
      "step = 5590: loss = -35.9376220703125\n",
      "step = 5595: loss = -35.97430419921875\n",
      "step = 5600: loss = -35.887916564941406\n",
      "step = 5600: Average Return = 1.0\n",
      " 0: 1 -  0: 5 -  0: 3 -  0:17 -  0: 6 -  0: 7 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5605: loss = -38.435035705566406\n",
      "step = 5610: loss = -34.638675689697266\n",
      "step = 5615: loss = -20.192764282226562\n",
      "step = 5620: loss = -35.71796417236328\n",
      "step = 5625: loss = -36.800010681152344\n",
      "step = 5630: loss = -37.20207977294922\n",
      "step = 5635: loss = -21.802274703979492\n",
      "step = 5640: loss = -25.249624252319336\n",
      "step = 5645: loss = -39.29273223876953\n",
      "step = 5650: loss = -38.933616638183594\n",
      "step = 5655: loss = -39.0283088684082\n",
      "step = 5660: loss = -38.746612548828125\n",
      "step = 5665: loss = -19.415481567382812\n",
      "step = 5670: loss = -38.89126968383789\n",
      "step = 5675: loss = -40.113433837890625\n",
      "step = 5680: loss = -39.39556121826172\n",
      "step = 5685: loss = -39.453704833984375\n",
      "step = 5690: loss = -39.228599548339844\n",
      "step = 5695: loss = -39.142208099365234\n",
      "step = 5700: loss = -37.34103012084961\n",
      "step = 5700: Average Return = 1.0\n",
      " 0: 2 -  0: 6 -  0: 4 -  0:15 -  0: 6 -  0: 8 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5705: loss = -39.031578063964844\n",
      "step = 5710: loss = -37.59165954589844\n",
      "step = 5715: loss = -38.03234100341797\n",
      "step = 5720: loss = -39.3258171081543\n",
      "step = 5725: loss = -39.03288269042969\n",
      "step = 5730: loss = -39.41477966308594\n",
      "step = 5735: loss = -38.006195068359375\n",
      "step = 5740: loss = -38.56990051269531\n",
      "step = 5745: loss = -41.46125411987305\n",
      "step = 5750: loss = -40.91295623779297\n",
      "step = 5755: loss = -40.452728271484375\n",
      "step = 5760: loss = -40.141754150390625\n",
      "step = 5765: loss = -20.115570068359375\n",
      "step = 5770: loss = -40.697505950927734\n",
      "step = 5775: loss = -39.01193618774414\n",
      "step = 5780: loss = -39.81562042236328\n",
      "step = 5785: loss = -39.79817199707031\n",
      "step = 5790: loss = -41.25448989868164\n",
      "step = 5795: loss = -41.09269714355469\n",
      "step = 5800: loss = -40.89838409423828\n",
      "step = 5800: Average Return = 1.0\n",
      " 0: 2 -  0: 8 -  0: 5 -  0:12 -  0: 8 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5805: loss = -20.883955001831055\n",
      "step = 5810: loss = -40.308284759521484\n",
      "step = 5815: loss = -40.20460510253906\n",
      "step = 5820: loss = -40.83348846435547\n",
      "step = 5825: loss = -41.606571197509766\n",
      "step = 5830: loss = -41.05997085571289\n",
      "step = 5835: loss = -24.373382568359375\n",
      "step = 5840: loss = -41.51721954345703\n",
      "step = 5845: loss = -42.269004821777344\n",
      "step = 5850: loss = -43.17045593261719\n",
      "step = 5855: loss = -41.50080108642578\n",
      "step = 5860: loss = -41.1536865234375\n",
      "step = 5865: loss = -40.243682861328125\n",
      "step = 5870: loss = -43.01555252075195\n",
      "step = 5875: loss = -41.84523010253906\n",
      "step = 5880: loss = -41.33718490600586\n",
      "step = 5885: loss = -42.518035888671875\n",
      "step = 5890: loss = -41.02172088623047\n",
      "step = 5895: loss = -41.72601318359375\n",
      "step = 5900: loss = -40.0546875\n",
      "step = 5900: Average Return = 1.0\n",
      " 0: 3 -  0: 8 -  0: 5 -  0: 9 -  0: 8 -  0: 8 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 5905: loss = -39.450172424316406\n",
      "step = 5910: loss = -42.33413314819336\n",
      "step = 5915: loss = -42.78399658203125\n",
      "step = 5920: loss = -42.08916473388672\n",
      "step = 5925: loss = -40.53112030029297\n",
      "step = 5930: loss = -41.96095275878906\n",
      "step = 5935: loss = -43.87698745727539\n",
      "step = 5940: loss = -41.559234619140625\n",
      "step = 5945: loss = -41.72605895996094\n",
      "step = 5950: loss = -40.55018997192383\n",
      "step = 5955: loss = -42.53253173828125\n",
      "step = 5960: loss = -43.48210144042969\n",
      "step = 5965: loss = -42.45384216308594\n",
      "step = 5970: loss = -41.668861389160156\n",
      "step = 5975: loss = -42.926795959472656\n",
      "step = 5980: loss = -41.44721221923828\n",
      "step = 5985: loss = -43.608642578125\n",
      "step = 5990: loss = -43.41127014160156\n",
      "step = 5995: loss = -43.02175521850586\n",
      "step = 6000: loss = -43.85194396972656\n",
      "step = 6000: Average Return = 1.0\n",
      " 0: 3 -  0: 8 -  0: 5 -  0:11 -  0: 9 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6005: loss = -42.56501770019531\n",
      "step = 6010: loss = -42.72144317626953\n",
      "step = 6015: loss = -43.725677490234375\n",
      "step = 6020: loss = -42.303123474121094\n",
      "step = 6025: loss = -41.58826446533203\n",
      "step = 6030: loss = -27.277420043945312\n",
      "step = 6035: loss = -41.948734283447266\n",
      "step = 6040: loss = -41.32502365112305\n",
      "step = 6045: loss = -43.35060119628906\n",
      "step = 6050: loss = -43.546817779541016\n",
      "step = 6055: loss = -43.07759475708008\n",
      "step = 6060: loss = -42.28633499145508\n",
      "step = 6065: loss = -27.252670288085938\n",
      "step = 6070: loss = -43.294410705566406\n",
      "step = 6075: loss = -43.620872497558594\n",
      "step = 6080: loss = -43.51588439941406\n",
      "step = 6085: loss = -43.057865142822266\n",
      "step = 6090: loss = -42.898048400878906\n",
      "step = 6095: loss = -29.447917938232422\n",
      "step = 6100: loss = -42.04597854614258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6100: Average Return = 1.0\n",
      " 0: 3 -  0: 8 -  0: 6 -  0:10 -  0: 9 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6105: loss = -25.262264251708984\n",
      "step = 6110: loss = -41.723960876464844\n",
      "step = 6115: loss = -41.348514556884766\n",
      "step = 6120: loss = -42.10622787475586\n",
      "step = 6125: loss = -44.51729965209961\n",
      "step = 6130: loss = -44.88883972167969\n",
      "step = 6135: loss = -43.10123062133789\n",
      "step = 6140: loss = -46.297279357910156\n",
      "step = 6145: loss = -42.97117233276367\n",
      "step = 6150: loss = -43.277122497558594\n",
      "step = 6155: loss = -44.364349365234375\n",
      "step = 6160: loss = -44.0761833190918\n",
      "step = 6165: loss = -44.733367919921875\n",
      "step = 6170: loss = -42.71491241455078\n",
      "step = 6175: loss = -43.36640930175781\n",
      "step = 6180: loss = -43.032684326171875\n",
      "step = 6185: loss = -44.24937438964844\n",
      "step = 6190: loss = -43.3284797668457\n",
      "step = 6195: loss = -44.273677825927734\n",
      "step = 6200: loss = -45.34071350097656\n",
      "step = 6200: Average Return = 1.0\n",
      " 0: 2 -  0: 8 -  0: 6 -  0:11 -  0:10 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6205: loss = -46.407745361328125\n",
      "step = 6210: loss = -44.83206558227539\n",
      "step = 6215: loss = -43.279815673828125\n",
      "step = 6220: loss = -32.78363800048828\n",
      "step = 6225: loss = -44.946929931640625\n",
      "step = 6230: loss = -46.438331604003906\n",
      "step = 6235: loss = -46.157135009765625\n",
      "step = 6240: loss = -44.91370391845703\n",
      "step = 6245: loss = -44.040802001953125\n",
      "step = 6250: loss = -44.19484329223633\n",
      "step = 6255: loss = -44.05192184448242\n",
      "step = 6260: loss = -45.16603088378906\n",
      "step = 6265: loss = -43.18274688720703\n",
      "step = 6270: loss = -43.86603927612305\n",
      "step = 6275: loss = -43.48373794555664\n",
      "step = 6280: loss = -44.07101821899414\n",
      "step = 6285: loss = -45.43353271484375\n",
      "step = 6290: loss = -45.70199966430664\n",
      "step = 6295: loss = -44.470794677734375\n",
      "step = 6300: loss = -44.33403015136719\n",
      "step = 6300: Average Return = 1.0\n",
      " 0: 2 -  0: 8 -  0: 6 -  0:10 -  0:10 -  0: 9 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6305: loss = -44.414588928222656\n",
      "step = 6310: loss = -46.1641845703125\n",
      "step = 6315: loss = -44.46995544433594\n",
      "step = 6320: loss = -45.697181701660156\n",
      "step = 6325: loss = -44.551788330078125\n",
      "step = 6330: loss = -44.307098388671875\n",
      "step = 6335: loss = -28.754344940185547\n",
      "step = 6340: loss = -46.383548736572266\n",
      "step = 6345: loss = -44.259666442871094\n",
      "step = 6350: loss = -45.67158508300781\n",
      "step = 6355: loss = -44.14512634277344\n",
      "step = 6360: loss = -46.08059310913086\n",
      "step = 6365: loss = -44.46788024902344\n",
      "step = 6370: loss = -45.56153106689453\n",
      "step = 6375: loss = -44.977935791015625\n",
      "step = 6380: loss = -45.67678451538086\n",
      "step = 6385: loss = -45.77506637573242\n",
      "step = 6390: loss = -45.661094665527344\n",
      "step = 6395: loss = -45.158267974853516\n",
      "step = 6400: loss = -34.96738052368164\n",
      "step = 6400: Average Return = 1.0\n",
      " 0: 2 -  0: 7 -  0: 6 -  0:11 -  0:11 -  0:10 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6405: loss = -45.521446228027344\n",
      "step = 6410: loss = -44.38551330566406\n",
      "step = 6415: loss = -45.6389045715332\n",
      "step = 6420: loss = -45.91279983520508\n",
      "step = 6425: loss = -46.022315979003906\n",
      "step = 6430: loss = -46.69240188598633\n",
      "step = 6435: loss = -47.890052795410156\n",
      "step = 6440: loss = -47.61376190185547\n",
      "step = 6445: loss = -45.71403884887695\n",
      "step = 6450: loss = -44.06021499633789\n",
      "step = 6455: loss = -44.758209228515625\n",
      "step = 6460: loss = -45.92159652709961\n",
      "step = 6465: loss = -45.542694091796875\n",
      "step = 6470: loss = -44.76200866699219\n",
      "step = 6475: loss = -45.66474914550781\n",
      "step = 6480: loss = -45.57335662841797\n",
      "step = 6485: loss = -46.27288818359375\n",
      "step = 6490: loss = -46.33306884765625\n",
      "step = 6495: loss = -46.887969970703125\n",
      "step = 6500: loss = -47.35106658935547\n",
      "step = 6500: Average Return = 4.0\n",
      " 0: 2 -  0: 7 -  0: 8 -  0:11 -  0:12 -  0:11 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6505: loss = -46.16290283203125\n",
      "step = 6510: loss = -45.693359375\n",
      "step = 6515: loss = -43.62078857421875\n",
      "step = 6520: loss = -46.757286071777344\n",
      "step = 6525: loss = -46.80303192138672\n",
      "step = 6530: loss = -46.07160186767578\n",
      "step = 6535: loss = -46.90143966674805\n",
      "step = 6540: loss = -47.05119323730469\n",
      "step = 6545: loss = -46.89931106567383\n",
      "step = 6550: loss = -44.97437286376953\n",
      "step = 6555: loss = -47.916664123535156\n",
      "step = 6560: loss = -48.11248779296875\n",
      "step = 6565: loss = -47.62763977050781\n",
      "step = 6570: loss = -46.81991195678711\n",
      "step = 6575: loss = -46.874080657958984\n",
      "step = 6580: loss = -48.98224639892578\n",
      "step = 6585: loss = -47.917850494384766\n",
      "step = 6590: loss = -48.22270202636719\n",
      "step = 6595: loss = -49.370567321777344\n",
      "step = 6600: loss = -47.69987869262695\n",
      "step = 6600: Average Return = 1.0\n",
      " 0: 2 -  0: 7 -  0: 7 -  0:13 -  0:16 -  0:13 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6605: loss = -50.732669830322266\n",
      "step = 6610: loss = -49.76115417480469\n",
      "step = 6615: loss = -50.51800537109375\n",
      "step = 6620: loss = -52.26243591308594\n",
      "step = 6625: loss = -51.80134201049805\n",
      "step = 6630: loss = -50.36695861816406\n",
      "step = 6635: loss = -33.98860549926758\n",
      "step = 6640: loss = -53.084228515625\n",
      "step = 6645: loss = -55.97649383544922\n",
      "step = 6650: loss = -56.03046417236328\n",
      "step = 6655: loss = -37.133392333984375\n",
      "step = 6660: loss = -56.70167922973633\n",
      "step = 6665: loss = -57.6949462890625\n",
      "step = 6670: loss = -59.22649383544922\n",
      "step = 6675: loss = -27.215248107910156\n",
      "step = 6680: loss = -58.45651626586914\n",
      "step = 6685: loss = -62.063419342041016\n",
      "step = 6690: loss = -61.319034576416016\n",
      "step = 6695: loss = -62.78408432006836\n",
      "step = 6700: loss = -62.748634338378906\n",
      "step = 6700: Average Return = 4.0\n",
      " 0: 6 -  0:22 -  0:57 -  0:58 -  2:20 -  1: 4 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6705: loss = -54.842506408691406\n",
      "step = 6710: loss = -64.5367431640625\n",
      "step = 6715: loss = -65.57611083984375\n",
      "step = 6720: loss = -63.89155578613281\n",
      "step = 6725: loss = -55.276119232177734\n",
      "step = 6730: loss = -61.82783508300781\n",
      "step = 6735: loss = -66.83206939697266\n",
      "step = 6740: loss = -66.59536743164062\n",
      "step = 6745: loss = -65.85345458984375\n",
      "step = 6750: loss = -66.13316345214844\n",
      "step = 6755: loss = -64.56643676757812\n",
      "step = 6760: loss = -67.77742767333984\n",
      "step = 6765: loss = -55.312705993652344\n",
      "step = 6770: loss = -59.70171356201172\n",
      "step = 6775: loss = -67.5499038696289\n",
      "step = 6780: loss = -64.7560806274414\n",
      "step = 6785: loss = -61.79277801513672\n",
      "step = 6790: loss = -35.47294616699219\n",
      "step = 6795: loss = -28.480466842651367\n",
      "step = 6800: loss = -30.708681106567383\n",
      "step = 6800: Average Return = 4.0\n",
      " 0: 6 -  3:24 -  4:31 -  5:32 -  5:53 -  5:51 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6805: loss = -15.07967758178711\n",
      "step = 6810: loss = -7.748594284057617\n",
      "step = 6815: loss = -25.00640869140625\n",
      "step = 6820: loss = -29.42718505859375\n",
      "step = 6825: loss = -40.07796096801758\n",
      "step = 6830: loss = -30.52666664123535\n",
      "step = 6835: loss = -19.705846786499023\n",
      "step = 6840: loss = -6.689741134643555\n",
      "step = 6845: loss = -27.653118133544922\n",
      "step = 6850: loss = -22.54857635498047\n",
      "step = 6855: loss = -32.7790641784668\n",
      "step = 6860: loss = -17.911701202392578\n",
      "step = 6865: loss = -17.70798110961914\n",
      "step = 6870: loss = -33.20942687988281\n",
      "step = 6875: loss = -30.367839813232422\n",
      "step = 6880: loss = -29.48821449279785\n",
      "step = 6885: loss = -18.413951873779297\n",
      "step = 6890: loss = -39.790992736816406\n",
      "step = 6895: loss = -12.730545043945312\n",
      "step = 6900: loss = -37.283023834228516\n",
      "step = 6900: Average Return = 4.0\n",
      " 0:12 -  3:29 -  4:49 -  5:35 -  5:54 -  5:52 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 6905: loss = -38.28042221069336\n",
      "step = 6910: loss = -16.996780395507812\n",
      "step = 6915: loss = -40.85245132446289\n",
      "step = 6920: loss = -18.39148712158203\n",
      "step = 6925: loss = -32.05903625488281\n",
      "step = 6930: loss = -35.24889373779297\n",
      "step = 6935: loss = -15.057703018188477\n",
      "step = 6940: loss = -36.21385955810547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6945: loss = -36.56512451171875\n",
      "step = 6950: loss = -26.364408493041992\n",
      "step = 6955: loss = -39.99595260620117\n",
      "step = 6960: loss = -36.48961639404297\n",
      "step = 6965: loss = -35.502445220947266\n",
      "step = 6970: loss = -38.98858642578125\n",
      "step = 6975: loss = -39.69908905029297\n",
      "step = 6980: loss = -29.729829788208008\n",
      "step = 6985: loss = -39.635955810546875\n",
      "step = 6990: loss = -30.32673454284668\n",
      "step = 6995: loss = -26.82474708557129\n",
      "step = 7000: loss = -28.241119384765625\n",
      "step = 7000: Average Return = 10.0\n",
      " 0: 5 -  3:34 -  4:39 -  5:33 -  5:53 -  5:54 - \n",
      " 0:14 -  0:12 -  0: 8 -  0:13 -  0:17 -  0:17 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 7005: loss = -29.900217056274414\n",
      "step = 7010: loss = -30.489105224609375\n",
      "step = 7015: loss = -36.540870666503906\n",
      "step = 7020: loss = -32.78793716430664\n",
      "step = 7025: loss = -28.728425979614258\n",
      "step = 7030: loss = -24.068822860717773\n",
      "step = 7035: loss = -36.44414520263672\n",
      "step = 7040: loss = -31.375911712646484\n",
      "step = 7045: loss = -19.482940673828125\n",
      "step = 7050: loss = -27.963809967041016\n",
      "step = 7055: loss = -20.869159698486328\n",
      "step = 7060: loss = -12.116493225097656\n",
      "step = 7065: loss = -26.07249641418457\n",
      "step = 7070: loss = -30.783613204956055\n",
      "step = 7075: loss = -30.70012092590332\n",
      "step = 7080: loss = -21.12506103515625\n",
      "step = 7085: loss = -30.977397918701172\n",
      "step = 7090: loss = -25.389610290527344\n",
      "step = 7095: loss = -24.097177505493164\n",
      "step = 7100: loss = -21.127676010131836\n",
      "step = 7100: Average Return = 10.0\n",
      " 0: 4 -  3:49 -  4:57 -  5:41 -  5:52 -  5:56 - \n",
      " 0:13 -  0:10 -  0:12 -  0:17 -  0:16 -  0:24 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 7105: loss = -26.08382797241211\n",
      "step = 7110: loss = -30.339975357055664\n",
      "step = 7115: loss = -23.847352981567383\n",
      "step = 7120: loss = -24.46274185180664\n",
      "step = 7125: loss = -22.534748077392578\n",
      "step = 7130: loss = -28.943878173828125\n",
      "step = 7135: loss = -25.775911331176758\n",
      "step = 7140: loss = -17.986255645751953\n",
      "step = 7145: loss = -25.299942016601562\n",
      "step = 7150: loss = -25.28374671936035\n",
      "step = 7155: loss = -22.105445861816406\n",
      "step = 7160: loss = -25.340553283691406\n",
      "step = 7165: loss = -18.624645233154297\n",
      "step = 7170: loss = -29.58916664123535\n",
      "step = 7175: loss = -15.241376876831055\n",
      "step = 7180: loss = -16.035173416137695\n",
      "step = 7185: loss = -18.432096481323242\n",
      "step = 7190: loss = -27.643646240234375\n",
      "step = 7195: loss = -21.530879974365234\n",
      "step = 7200: loss = -15.866008758544922\n",
      "step = 7200: Average Return = 10.0\n",
      " 0: 3 -  3:42 -  5:10 -  5:31 -  5:40 -  5:57 - \n",
      " 0:25 -  0:25 -  0:13 -  0:27 -  0:18 -  0:18 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 7205: loss = -18.430274963378906\n",
      "step = 7210: loss = -17.489267349243164\n",
      "step = 7215: loss = -23.69875717163086\n",
      "step = 7220: loss = -17.096410751342773\n",
      "step = 7225: loss = -24.094018936157227\n",
      "step = 7230: loss = -19.21341896057129\n",
      "step = 7235: loss = -18.802980422973633\n",
      "step = 7240: loss = -17.955684661865234\n",
      "step = 7245: loss = -18.01629638671875\n",
      "step = 7250: loss = -3.5781936645507812\n",
      "step = 7255: loss = -18.179473876953125\n",
      "step = 7260: loss = -11.857555389404297\n",
      "step = 7265: loss = -18.105093002319336\n",
      "step = 7270: loss = -22.877628326416016\n",
      "step = 7275: loss = -14.308090209960938\n",
      "step = 7280: loss = -15.347953796386719\n",
      "step = 7285: loss = -19.068035125732422\n",
      "step = 7290: loss = -5.378269195556641\n",
      "step = 7295: loss = -11.497970581054688\n",
      "step = 7300: loss = -12.050975799560547\n",
      "step = 7300: Average Return = 11.0\n",
      " 0: 2 -  3:47 -  5:11 -  5:24 -  5:36 -  5:57 - \n",
      " 0:23 -  0:26 -  0:10 -  0:31 -  0:18 -  0:20 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 7305: loss = -7.919410705566406\n",
      "step = 7310: loss = -12.473857879638672\n",
      "step = 7315: loss = -7.619144439697266\n",
      "step = 7320: loss = -9.780302047729492\n",
      "step = 7325: loss = -2.4171905517578125\n",
      "step = 7330: loss = -6.320941925048828\n",
      "step = 7335: loss = -9.314891815185547\n",
      "step = 7340: loss = -14.587696075439453\n",
      "step = 7345: loss = -5.961631774902344\n",
      "step = 7350: loss = -10.63189697265625\n",
      "step = 7355: loss = -1.3464584350585938\n",
      "step = 7360: loss = -4.628578186035156\n",
      "step = 7365: loss = -2.069042205810547\n",
      "step = 7370: loss = -3.517608642578125\n",
      "step = 7375: loss = -11.172508239746094\n",
      "step = 7380: loss = -3.0159530639648438\n",
      "step = 7385: loss = 0.36383819580078125\n",
      "step = 7390: loss = 0.9871177673339844\n",
      "step = 7395: loss = 7.269866943359375\n",
      "step = 7400: loss = -0.6296958923339844\n",
      "step = 7400: Average Return = 11.0\n",
      " 0: 1 -  3:36 -  5: 9 -  5:23 -  5:38 -  5:58 - \n",
      " 0:14 -  0:22 -  0: 5 -  0:24 -  0:16 -  0:21 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 7405: loss = -1.4947319030761719\n",
      "step = 7410: loss = 2.0470733642578125\n",
      "step = 7415: loss = 6.256214141845703\n",
      "step = 7420: loss = 4.712394714355469\n",
      "step = 7425: loss = -1.3535232543945312\n",
      "step = 7430: loss = 3.2399864196777344\n",
      "step = 7435: loss = 4.288509368896484\n",
      "step = 7440: loss = -0.039154052734375\n",
      "step = 7445: loss = 7.251441955566406\n",
      "step = 7450: loss = -1.6941757202148438\n",
      "step = 7455: loss = 5.991062164306641\n",
      "step = 7460: loss = 5.752033233642578\n",
      "step = 7465: loss = 3.6022720336914062\n",
      "step = 7470: loss = -0.486663818359375\n",
      "step = 7475: loss = 5.821266174316406\n",
      "step = 7480: loss = 1.2224197387695312\n",
      "step = 7485: loss = 7.560665130615234\n",
      "step = 7490: loss = 6.853935241699219\n",
      "step = 7495: loss = 4.222877502441406\n",
      "step = 7500: loss = 14.112525939941406\n",
      "step = 7500: Average Return = 2.0\n",
      " 0: 1 -  3:41 -  5:18 -  5:16 -  5:37 -  5:58 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 7505: loss = 5.102874755859375\n",
      "step = 7510: loss = 11.15700912475586\n",
      "step = 7515: loss = 9.420757293701172\n",
      "step = 7520: loss = 6.326335906982422\n",
      "step = 7525: loss = 16.325904846191406\n",
      "step = 7530: loss = 11.991199493408203\n",
      "step = 7535: loss = 15.4708251953125\n",
      "step = 7540: loss = 15.105812072753906\n",
      "step = 7545: loss = 11.715560913085938\n",
      "step = 7550: loss = 13.111900329589844\n",
      "step = 7555: loss = 21.881980895996094\n",
      "step = 7560: loss = 21.936626434326172\n",
      "step = 7565: loss = 17.571720123291016\n",
      "step = 7570: loss = 11.324275970458984\n",
      "step = 7575: loss = 17.34461212158203\n",
      "step = 7580: loss = 18.679882049560547\n",
      "step = 7585: loss = 20.22083282470703\n",
      "step = 7590: loss = 12.527595520019531\n",
      "step = 7595: loss = 11.5738525390625\n",
      "step = 7600: loss = 15.21456527709961\n",
      "step = 7600: Average Return = 12.0\n",
      " 0: 1 -  3:44 -  5: 8 -  5:26 -  5:41 -  5:58 - \n",
      " 0: 6 -  0:20 -  0:40 -  0:17 -  0:14 -  0:12 - \n",
      " 0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 -  0: 0 - \n",
      "\n",
      "step = 7605: loss = 19.070911407470703\n",
      "step = 7610: loss = 27.944259643554688\n",
      "step = 7615: loss = 16.803264617919922\n",
      "step = 7620: loss = 16.999523162841797\n",
      "step = 7625: loss = 16.842304229736328\n",
      "step = 7630: loss = 18.69489288330078\n",
      "step = 7635: loss = 11.183143615722656\n",
      "step = 7640: loss = 11.674674987792969\n",
      "step = 7645: loss = 23.34560775756836\n",
      "step = 7650: loss = 9.722148895263672\n",
      "step = 7655: loss = 16.33624267578125\n",
      "step = 7660: loss = 13.50661849975586\n",
      "step = 7665: loss = 16.186077117919922\n",
      "step = 7670: loss = 18.5269775390625\n",
      "step = 7675: loss = 25.294044494628906\n",
      "step = 7680: loss = 19.327560424804688\n",
      "step = 7685: loss = 22.919818878173828\n",
      "step = 7690: loss = 21.39126968383789\n",
      "step = 7695: loss = 141.212890625\n",
      "step = 7700: loss = 27.319873809814453\n",
      "step = 7700: Average Return = 235.0\n",
      " 0: 0 -  3:47 -  5:12 -  5:29 -  5:38 -  5:59 - \n",
      " 0: 1 -  3:35 -  5: 0 -  5:13 -  5:20 -  5:50 - \n",
      " 0: 1 -  3:47 -  5:13 -  5:27 -  5:31 -  5:57 - \n",
      "\n",
      "step = 7705: loss = 152.10549926757812\n",
      "step = 7710: loss = 28.994186401367188\n",
      "step = 7715: loss = 30.849063873291016\n",
      "step = 7720: loss = 38.182106018066406\n",
      "step = 7725: loss = 27.988265991210938\n",
      "step = 7730: loss = 32.29668045043945\n",
      "step = 7735: loss = 56.23234176635742\n",
      "step = 7740: loss = 51.805397033691406\n",
      "step = 7745: loss = 20.548137664794922\n",
      "step = 7750: loss = 35.97482681274414\n",
      "step = 7755: loss = 49.3246955871582\n",
      "step = 7760: loss = 40.09087371826172\n",
      "step = 7765: loss = 39.659427642822266\n",
      "step = 7770: loss = 33.387569427490234\n",
      "step = 7775: loss = 42.930686950683594\n",
      "step = 7780: loss = 170.98138427734375\n",
      "step = 7785: loss = 64.05931091308594\n",
      "step = 7790: loss = 75.62596893310547\n",
      "step = 7795: loss = 72.40941619873047\n",
      "step = 7800: loss = 68.04335021972656\n",
      "step = 7800: Average Return = 232.0\n",
      " 0: 0 -  3:49 -  5:12 -  5:29 -  5:39 -  5:59 - \n",
      " 0: 0 -  3:44 -  5: 9 -  5:24 -  5:34 -  5:56 - \n",
      " 0: 0 -  3:50 -  5:18 -  5:31 -  5:40 -  5:58 - \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 7805: loss = 71.5701904296875\n",
      "step = 7810: loss = 45.75348663330078\n",
      "step = 7815: loss = 172.54541015625\n",
      "step = 7820: loss = 164.9761962890625\n",
      "step = 7825: loss = 65.12545776367188\n",
      "step = 7830: loss = 77.27005004882812\n",
      "step = 7835: loss = 175.35028076171875\n",
      "step = 7840: loss = 178.077880859375\n",
      "step = 7845: loss = 77.62174987792969\n",
      "step = 7850: loss = 295.5406188964844\n",
      "step = 7855: loss = 122.4742202758789\n",
      "step = 7860: loss = 113.54364776611328\n",
      "step = 7865: loss = 64.3555908203125\n",
      "step = 7870: loss = 259.64215087890625\n",
      "step = 7875: loss = 111.2965087890625\n",
      "step = 7880: loss = 313.5599365234375\n",
      "step = 7885: loss = 184.04714965820312\n",
      "step = 7890: loss = 103.69575500488281\n",
      "step = 7895: loss = 189.59805297851562\n",
      "step = 7900: loss = 96.34716033935547\n",
      "step = 7900: Average Return = 230.0\n",
      " 0: 0 -  4:30 -  5:28 -  5:35 -  5:48 -  5:59 - \n",
      " 0: 0 -  4:27 -  5:26 -  5:31 -  5:46 -  5:57 - \n",
      " 0: 0 -  4:31 -  5:31 -  5:36 -  5:48 -  5:58 - \n",
      "\n",
      "step = 7905: loss = 183.26657104492188\n",
      "step = 7910: loss = 138.5367431640625\n",
      "step = 7915: loss = 131.51611328125\n",
      "step = 7920: loss = 137.96490478515625\n",
      "step = 7925: loss = 264.2318115234375\n",
      "step = 7930: loss = 234.1893310546875\n",
      "step = 7935: loss = 148.8995361328125\n",
      "step = 7940: loss = 226.05079650878906\n",
      "step = 7945: loss = 123.81698608398438\n",
      "step = 7950: loss = 395.07501220703125\n",
      "step = 7955: loss = 243.3009490966797\n",
      "step = 7960: loss = 168.90118408203125\n",
      "step = 7965: loss = 127.70580291748047\n",
      "step = 7970: loss = 150.38525390625\n",
      "step = 7975: loss = 163.9571075439453\n",
      "step = 7980: loss = 270.9503173828125\n",
      "step = 7985: loss = 345.80535888671875\n",
      "step = 7990: loss = 394.1605224609375\n",
      "step = 7995: loss = 144.159912109375\n",
      "step = 8000: loss = 173.15521240234375\n",
      "step = 8000: Average Return = 245.0\n",
      " 0: 0 -  4:24 -  5:16 -  5:38 -  5:44 -  5:59 - \n",
      " 0: 0 -  4:18 -  5:12 -  5:34 -  5:42 -  5:57 - \n",
      " 0: 0 -  4:19 -  5:17 -  5:36 -  5:44 -  5:58 - \n",
      "\n",
      "step = 8005: loss = 172.76358032226562\n",
      "step = 8010: loss = 170.86399841308594\n",
      "step = 8015: loss = 187.52540588378906\n",
      "step = 8020: loss = 165.11822509765625\n",
      "step = 8025: loss = 334.5722961425781\n",
      "step = 8030: loss = 314.7967834472656\n",
      "step = 8035: loss = 286.45196533203125\n",
      "step = 8040: loss = 261.5502014160156\n",
      "step = 8045: loss = 361.77496337890625\n",
      "step = 8050: loss = 325.158935546875\n",
      "step = 8055: loss = 399.04962158203125\n",
      "step = 8060: loss = 343.35162353515625\n",
      "step = 8065: loss = 223.6692352294922\n",
      "step = 8070: loss = 240.13937377929688\n",
      "step = 8075: loss = 264.9687194824219\n",
      "step = 8080: loss = 614.6555786132812\n",
      "step = 8085: loss = 315.0198669433594\n",
      "step = 8090: loss = 198.7435302734375\n",
      "step = 8095: loss = 374.9659423828125\n",
      "step = 8100: loss = 387.5693359375\n",
      "step = 8100: Average Return = 232.0\n",
      " 0: 0 -  4: 6 -  5:23 -  5:34 -  5:41 -  5:59 - \n",
      " 0: 0 -  4: 0 -  5:21 -  5:30 -  5:38 -  5:58 - \n",
      " 0: 0 -  4: 3 -  5:25 -  5:33 -  5:41 -  5:59 - \n",
      "\n",
      "step = 8105: loss = 523.6929321289062\n",
      "step = 8110: loss = 293.7532958984375\n",
      "step = 8115: loss = 268.9990539550781\n",
      "step = 8120: loss = 260.7015686035156\n",
      "step = 8125: loss = 382.7662048339844\n",
      "step = 8130: loss = 281.5954284667969\n",
      "step = 8135: loss = 350.49725341796875\n",
      "step = 8140: loss = 293.7431945800781\n",
      "step = 8145: loss = 260.0285949707031\n",
      "step = 8150: loss = 504.15728759765625\n",
      "step = 8155: loss = 309.861328125\n",
      "step = 8160: loss = 406.7275695800781\n",
      "step = 8165: loss = 399.48675537109375\n",
      "step = 8170: loss = 306.7106018066406\n",
      "step = 8175: loss = 477.4834289550781\n",
      "step = 8180: loss = 358.2527160644531\n",
      "step = 8185: loss = 417.08135986328125\n",
      "step = 8190: loss = 337.6899719238281\n",
      "step = 8195: loss = 398.2867126464844\n",
      "step = 8200: loss = 370.5596008300781\n",
      "step = 8200: Average Return = 238.0\n",
      " 0: 0 -  4:17 -  5:19 -  5:30 -  5:53 -  5:59 - \n",
      " 0: 0 -  4: 8 -  5:19 -  5:25 -  5:53 -  5:58 - \n",
      " 0: 0 -  4: 8 -  5:21 -  5:28 -  5:53 -  5:59 - \n",
      "\n",
      "step = 8205: loss = 292.4112548828125\n",
      "step = 8210: loss = 485.385986328125\n",
      "step = 8215: loss = 457.1163024902344\n",
      "step = 8220: loss = 472.8167419433594\n",
      "step = 8225: loss = 475.82611083984375\n",
      "step = 8230: loss = 424.0362548828125\n",
      "step = 8235: loss = 426.7789001464844\n",
      "step = 8240: loss = 472.1531677246094\n",
      "step = 8245: loss = 459.6358947753906\n",
      "step = 8250: loss = 506.6939697265625\n",
      "step = 8255: loss = 525.8290405273438\n",
      "step = 8260: loss = 390.5731201171875\n",
      "step = 8265: loss = 476.7491760253906\n",
      "step = 8270: loss = 485.9186706542969\n",
      "step = 8275: loss = 419.67340087890625\n",
      "step = 8280: loss = 515.3568115234375\n",
      "step = 8285: loss = 508.4002685546875\n",
      "step = 8290: loss = 638.12939453125\n",
      "step = 8295: loss = 567.8638916015625\n",
      "step = 8300: loss = 549.4959716796875\n",
      "step = 8300: Average Return = 248.0\n",
      " 0: 0 -  4:20 -  5:13 -  5:27 -  5:54 -  5:59 - \n",
      " 0: 0 -  4:16 -  5:13 -  5:23 -  5:54 -  5:58 - \n",
      " 0: 0 -  4:16 -  5:14 -  5:24 -  5:54 -  5:59 - \n",
      "\n",
      "step = 8305: loss = 562.043212890625\n",
      "step = 8310: loss = 443.5259704589844\n",
      "step = 8315: loss = 550.6092529296875\n",
      "step = 8320: loss = 705.4662475585938\n",
      "step = 8325: loss = 573.9957275390625\n",
      "step = 8330: loss = 556.8795166015625\n",
      "step = 8335: loss = 494.57745361328125\n",
      "step = 8340: loss = 586.9083862304688\n",
      "step = 8345: loss = 583.9657592773438\n",
      "step = 8350: loss = 582.2039184570312\n",
      "step = 8355: loss = 578.7752075195312\n",
      "step = 8360: loss = 664.4721069335938\n",
      "step = 8365: loss = 516.1425170898438\n",
      "step = 8370: loss = 792.3106079101562\n",
      "step = 8375: loss = 705.60205078125\n",
      "step = 8380: loss = 707.6051635742188\n",
      "step = 8385: loss = 678.0220947265625\n",
      "step = 8390: loss = 711.8760375976562\n",
      "step = 8395: loss = 657.830078125\n",
      "step = 8400: loss = 1012.0938110351562\n",
      "step = 8400: Average Return = 248.0\n",
      " 0: 0 -  4:19 -  5: 7 -  5:26 -  5:56 -  5:59 - \n",
      " 0: 0 -  4:12 -  5: 7 -  5:23 -  5:56 -  5:58 - \n",
      " 0: 0 -  4:10 -  5: 7 -  5:24 -  5:56 -  5:59 - \n",
      "\n",
      "step = 8405: loss = 892.2761840820312\n",
      "step = 8410: loss = 665.8392333984375\n",
      "step = 8415: loss = 748.159912109375\n",
      "step = 8420: loss = 634.6707763671875\n",
      "step = 8425: loss = 661.83203125\n",
      "step = 8430: loss = 645.9583129882812\n",
      "step = 8435: loss = 827.2459716796875\n",
      "step = 8440: loss = 881.0872802734375\n",
      "step = 8445: loss = 694.2362060546875\n",
      "step = 8450: loss = 801.537353515625\n",
      "step = 8455: loss = 706.1409301757812\n",
      "step = 8460: loss = 721.4757690429688\n",
      "step = 8465: loss = 725.4821166992188\n",
      "step = 8470: loss = 910.3594360351562\n",
      "step = 8475: loss = 871.8557739257812\n",
      "step = 8480: loss = 900.1076049804688\n",
      "step = 8485: loss = 933.9470825195312\n",
      "step = 8490: loss = 852.0213012695312\n",
      "step = 8495: loss = 658.3388061523438\n",
      "step = 8500: loss = 814.9435424804688\n",
      "step = 8500: Average Return = 250.0\n",
      " 0: 0 -  4:23 -  5:11 -  5:20 -  5:57 -  5:59 - \n",
      " 0: 0 -  4:16 -  5: 9 -  5:18 -  5:57 -  5:58 - \n",
      " 0: 0 -  4:14 -  5:10 -  5:18 -  5:57 -  5:59 - \n",
      "\n",
      "step = 8505: loss = 826.8130493164062\n",
      "step = 8510: loss = 885.6085815429688\n",
      "step = 8515: loss = 886.4600830078125\n",
      "step = 8520: loss = 1026.486328125\n",
      "step = 8525: loss = 907.751953125\n",
      "step = 8530: loss = 878.8916015625\n",
      "step = 8535: loss = 901.1632690429688\n",
      "step = 8540: loss = 889.6112670898438\n",
      "step = 8545: loss = 833.81787109375\n",
      "step = 8550: loss = 801.9677124023438\n",
      "step = 8555: loss = 938.283935546875\n",
      "step = 8560: loss = 917.705810546875\n",
      "step = 8565: loss = 925.06689453125\n",
      "step = 8570: loss = 1235.499267578125\n",
      "step = 8575: loss = 944.9276733398438\n",
      "step = 8580: loss = 1000.7622680664062\n",
      "step = 8585: loss = 1091.356689453125\n",
      "step = 8590: loss = 884.4569091796875\n",
      "step = 8595: loss = 921.608642578125\n",
      "step = 8600: loss = 1067.609130859375\n",
      "step = 8600: Average Return = 247.0\n",
      " 0: 0 -  4:20 -  5: 3 -  5:28 -  5:57 -  5:59 - \n",
      " 0: 0 -  4:14 -  4:58 -  5:24 -  5:57 -  5:59 - \n",
      " 0: 0 -  4:13 -  5: 0 -  5:25 -  5:57 -  5:59 - \n",
      "\n",
      "step = 8605: loss = 1172.2645263671875\n",
      "step = 8610: loss = 1095.2626953125\n",
      "step = 8615: loss = 1111.5977783203125\n",
      "step = 8620: loss = 1076.8038330078125\n",
      "step = 8625: loss = 1064.4200439453125\n",
      "step = 8630: loss = 1115.7357177734375\n",
      "step = 8635: loss = 1192.071533203125\n",
      "step = 8640: loss = 1053.8988037109375\n",
      "step = 8645: loss = 1163.3553466796875\n",
      "step = 8650: loss = 1051.935546875\n",
      "step = 8655: loss = 1143.5999755859375\n",
      "step = 8660: loss = 1112.3995361328125\n",
      "step = 8665: loss = 1038.51904296875\n",
      "step = 8670: loss = 1154.009765625\n",
      "step = 8675: loss = 1212.5242919921875\n",
      "step = 8680: loss = 1217.8653564453125\n",
      "step = 8685: loss = 1434.5888671875\n",
      "step = 8690: loss = 1377.698974609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 8695: loss = 1241.0748291015625\n",
      "step = 8700: loss = 1358.6055908203125\n",
      "step = 8700: Average Return = 238.0\n",
      " 0: 0 -  4: 9 -  5: 2 -  5:30 -  5:57 -  5:59 - \n",
      " 0: 0 -  4: 0 -  4:57 -  5:28 -  5:57 -  5:59 - \n",
      " 0: 0 -  4: 2 -  4:59 -  5:29 -  5:57 -  5:59 - \n",
      "\n",
      "step = 8705: loss = 1078.7220458984375\n",
      "step = 8710: loss = 1388.2723388671875\n",
      "step = 8715: loss = 1260.788818359375\n",
      "step = 8720: loss = 1258.1077880859375\n",
      "step = 8725: loss = 1341.5950927734375\n",
      "step = 8730: loss = 1269.9561767578125\n",
      "step = 8735: loss = 1273.90869140625\n",
      "step = 8740: loss = 1239.695556640625\n",
      "step = 8745: loss = 1284.626220703125\n",
      "step = 8750: loss = 1285.44287109375\n",
      "step = 8755: loss = 1209.5830078125\n",
      "step = 8760: loss = 1666.9178466796875\n",
      "step = 8765: loss = 1303.3173828125\n",
      "step = 8770: loss = 1284.683837890625\n",
      "step = 8775: loss = 1425.5301513671875\n",
      "step = 8780: loss = 1284.6234130859375\n",
      "step = 8785: loss = 1214.570068359375\n",
      "step = 8790: loss = 1306.1007080078125\n",
      "step = 8795: loss = 1433.6278076171875\n",
      "step = 8800: loss = 1239.47021484375\n",
      "step = 8800: Average Return = 250.0\n",
      " 0: 0 -  4:19 -  5:11 -  5:22 -  5:57 -  5:59 - \n",
      " 0: 0 -  4:14 -  5: 5 -  5:21 -  5:56 -  5:59 - \n",
      " 0: 0 -  4:15 -  5: 7 -  5:21 -  5:56 -  5:59 - \n",
      "\n",
      "step = 8805: loss = 1200.5445556640625\n",
      "step = 8810: loss = 1480.0513916015625\n",
      "step = 8815: loss = 1537.9908447265625\n",
      "step = 8820: loss = 1193.1351318359375\n",
      "step = 8825: loss = 1572.7242431640625\n",
      "step = 8830: loss = 1364.3302001953125\n",
      "step = 8835: loss = 1345.14990234375\n",
      "step = 8840: loss = 1570.687255859375\n",
      "step = 8845: loss = 1404.8631591796875\n",
      "step = 8850: loss = 1426.2581787109375\n",
      "step = 8855: loss = 1535.462890625\n",
      "step = 8860: loss = 1428.0390625\n",
      "step = 8865: loss = 1543.004150390625\n",
      "step = 8870: loss = 1368.5093994140625\n",
      "step = 8875: loss = 1359.2998046875\n",
      "step = 8880: loss = 1554.0242919921875\n",
      "step = 8885: loss = 1466.08154296875\n",
      "step = 8890: loss = 1414.3399658203125\n",
      "step = 8895: loss = 1430.7685546875\n",
      "step = 8900: loss = 1382.07373046875\n",
      "step = 8900: Average Return = 235.0\n",
      " 0: 0 -  4:29 -  5:18 -  5:29 -  5:56 -  5:59 - \n",
      " 0: 0 -  4:29 -  5:12 -  5:29 -  5:56 -  5:59 - \n",
      " 0: 0 -  4:31 -  5:15 -  5:29 -  5:56 -  5:59 - \n",
      "\n",
      "step = 8905: loss = 1593.923828125\n",
      "step = 8910: loss = 1587.6273193359375\n",
      "step = 8915: loss = 1650.9964599609375\n",
      "step = 8920: loss = 1353.14794921875\n",
      "step = 8925: loss = 1593.1455078125\n",
      "step = 8930: loss = 1531.768310546875\n",
      "step = 8935: loss = 1470.8243408203125\n",
      "step = 8940: loss = 1639.370361328125\n",
      "step = 8945: loss = 1614.54541015625\n",
      "step = 8950: loss = 1460.640869140625\n",
      "step = 8955: loss = 1485.046630859375\n",
      "step = 8960: loss = 1528.405517578125\n",
      "step = 8965: loss = 1728.29638671875\n",
      "step = 8970: loss = 1634.9456787109375\n",
      "step = 8975: loss = 1652.8492431640625\n",
      "step = 8980: loss = 1693.818359375\n",
      "step = 8985: loss = 1793.0855712890625\n",
      "step = 8990: loss = 1641.8360595703125\n",
      "step = 8995: loss = 1742.1041259765625\n",
      "step = 9000: loss = 1635.138916015625\n",
      "step = 9000: Average Return = 235.0\n",
      " 0: 0 -  4:23 -  5:17 -  5:27 -  5:56 -  5:59 - \n",
      " 0: 0 -  4:28 -  5:12 -  5:29 -  5:55 -  5:59 - \n",
      " 0: 0 -  4:29 -  5:14 -  5:29 -  5:55 -  5:59 - \n",
      "\n",
      "step = 9005: loss = 1640.1192626953125\n",
      "step = 9010: loss = 1798.62646484375\n",
      "step = 9015: loss = 1496.166015625\n",
      "step = 9020: loss = 1829.6802978515625\n",
      "step = 9025: loss = 1812.330322265625\n",
      "step = 9030: loss = 1855.7021484375\n",
      "step = 9035: loss = 1652.275390625\n",
      "step = 9040: loss = 1820.8946533203125\n",
      "step = 9045: loss = 1873.1531982421875\n",
      "step = 9050: loss = 1931.606689453125\n",
      "step = 9055: loss = 1947.82177734375\n",
      "step = 9060: loss = 1823.9510498046875\n",
      "step = 9065: loss = 1722.3072509765625\n",
      "step = 9070: loss = 1669.5679931640625\n",
      "step = 9075: loss = 1750.061767578125\n",
      "step = 9080: loss = 1766.8128662109375\n",
      "step = 9085: loss = 1683.66064453125\n",
      "step = 9090: loss = 2058.939453125\n",
      "step = 9095: loss = 1729.9031982421875\n",
      "step = 9100: loss = 2340.3623046875\n",
      "step = 9100: Average Return = 249.0\n",
      " 0: 0 -  4:16 -  5: 8 -  5:22 -  5:55 -  5:59 - \n",
      " 0: 0 -  4:17 -  5: 0 -  5:21 -  5:54 -  5:59 - \n",
      " 0: 0 -  4:17 -  5: 2 -  5:21 -  5:54 -  5:59 - \n",
      "\n",
      "step = 9105: loss = 1798.684326171875\n",
      "step = 9110: loss = 1837.765625\n",
      "step = 9115: loss = 1943.01953125\n",
      "step = 9120: loss = 1914.514404296875\n",
      "step = 9125: loss = 2133.82568359375\n",
      "step = 9130: loss = 1876.47998046875\n",
      "step = 9135: loss = 1746.8555908203125\n",
      "step = 9140: loss = 2000.5823974609375\n",
      "step = 9145: loss = 2021.87060546875\n",
      "step = 9150: loss = 2005.654296875\n",
      "step = 9155: loss = 2143.425048828125\n",
      "step = 9160: loss = 1800.50732421875\n",
      "step = 9165: loss = 1998.024169921875\n",
      "step = 9170: loss = 2404.17626953125\n",
      "step = 9175: loss = 1870.6552734375\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# Optimize by wrapping some of the code in a graph using TF function.\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "collect_driver.run = common.function(collect_driver.run)\n",
    "\n",
    "# Reset the train step\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, eval_policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_driver.run()\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = tf_agent.train(experience)\n",
    "\n",
    "  step = tf_agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, eval_policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    eval_py_env.render()\n",
    "    print('')\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir='./temp2',\n",
    "    max_to_keep=1,\n",
    "    agent=tf_agent,\n",
    "    policy=tf_agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=global_step\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_checkpointer.save(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe768201650>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_checkpointer.initialize_or_restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.simulator import Simulator\n",
    "from simulation.utils import DemoNetwork1\n",
    "\n",
    "sim = Simulator(DemoNetwork1)\n",
    "\n",
    "tt = [[1,15,18,30,40,50],\n",
    "     [1,15,18,30,40,50],\n",
    "     [1,15,18,30,40,50]]\n",
    "\n",
    "results = sim.evaluate_timetable(tt)\n",
    "total_reward = results['passenger_increase']['reward_total'] + results['trains_delay']['reward_total'] + results['trains_increase']['reward_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.132577554090005"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passenger_increase': {'1': 0.932765809589993,\n",
       "  '5': 0.9848651623555311,\n",
       "  '10': 0.8457620347559758,\n",
       "  '25': 0.3661007667031763,\n",
       "  '50': 0.18559928443649373,\n",
       "  '100': 0.09357134090013501,\n",
       "  'reward_total': 3.408664398741305},\n",
       " 'trains_increase': {'0': 0.932765809589993,\n",
       "  '1': 0.932765809589993,\n",
       "  '2': 0.9534398888116747,\n",
       "  '4': 0.9675121612230716,\n",
       "  'reward_total': 3.786483669214732},\n",
       " 'trains_delay': {'5': 0.9904375343973583,\n",
       "  '10': 0.9950396164857847,\n",
       "  '30': 0.6328884021512838,\n",
       "  '60': 0.3190639330995414,\n",
       "  'reward_total': 2.937429486133968},\n",
       " 'timetables': [[1, 15, 18, 30, 40, 50],\n",
       "  [1, 15, 18, 30, 40, 50],\n",
       "  [1, 15, 18, 30, 40, 50]]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.simulator import Simulator\n",
    "from simulation.utils import DemoNetwork1\n",
    "\n",
    "sim = Simulator(DemoNetwork1)\n",
    "\n",
    "tt = [[0,1,2,3,4,5],\n",
    "     [0,1,2,3,4,5],\n",
    "     [0,1,2,3,4,5]]\n",
    "\n",
    "results = sim.evaluate_timetable(tt)\n",
    "total_reward = results['passenger_increase']['reward_total'] + results['trains_delay']['reward_total'] + results['trains_increase']['reward_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.526618475757955"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passenger_increase': {'1': 0.9320708825573315,\n",
       "  '5': 0.9846931755641167,\n",
       "  '10': 0.8451960849590519,\n",
       "  '25': 0.3656509153497105,\n",
       "  '50': 0.18536270773378963,\n",
       "  '100': 0.09350189600708014,\n",
       "  'reward_total': 3.406475662171081},\n",
       " 'trains_increase': {'0': 0.9320708825573315,\n",
       "  '1': 0.9320708825573315,\n",
       "  '2': 0.9454482279360668,\n",
       "  '4': 0.9515288394718554,\n",
       "  'reward_total': 3.761118832522585},\n",
       " 'trains_delay': {'5': 0.9871697853604843,\n",
       "  '10': 0.8747253478926693,\n",
       "  '30': 0.33019062283136713,\n",
       "  '60': 0.166938224979768,\n",
       "  'reward_total': 2.359023981064289},\n",
       " 'timetables': [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}